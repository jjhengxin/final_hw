{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Environment does not support cv2.imshow() or PIL Image.show()\n",
      "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
      "\n",
      "\n",
      "image 1/1 D:\\college\\2024_spring\\AI\\project2\\dogs\\me.jpg: 448x640 1 person, 224.4ms\n",
      "Speed: 4.2ms preprocess, 224.4ms inference, 0.0ms postprocess per image at shape (1, 3, 448, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict8\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "results = model(source=\"me.jpg\", show=True, conf=0.1, save=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "获取视频的总帧数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total frames in the video: 251\n"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "  \n",
    "cap = cv2.VideoCapture(\"badminton.mp4\")  \n",
    "  \n",
    "if cap.isOpened():  \n",
    "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  \n",
    "    print(\"Total frames in the video:\", total_frames)  \n",
    "else:  \n",
    "    print(\"Error opening video file\")  \n",
    "  \n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面进行视频逐帧分析，注释掉的部分是用于生成视频片段的，存在bug。后改为生成照片集。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 1 person, 250.3ms\n",
      "Speed: 5.9ms preprocess, 250.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([647.4560, 440.0916]) tensor([654.5205, 445.1878])\n",
      "tensor([594.1923, 433.7973]) tensor([608.0629, 439.9031])\n",
      "1\n",
      "tensor([648.9238, 427.3699]) tensor([626.0655, 426.2244])\n",
      "tensor([647.4560, 440.0916]) tensor([594.1923, 433.7973])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 216.1ms\n",
      "Speed: 3.0ms preprocess, 216.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([655.9489, 458.5134]) tensor([656.4591, 453.1742])\n",
      "tensor([587.5693, 434.0476]) tensor([602.6402, 438.7481])\n",
      "tensor([648.2850, 431.5073]) tensor([621.5196, 428.3117])\n",
      "tensor([655.9489, 458.5134]) tensor([587.5693, 434.0476])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 223.4ms\n",
      "Speed: 2.0ms preprocess, 223.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([653.3350, 464.8552]) tensor([655.5404, 454.8878])\n",
      "tensor([597.3972, 446.7994]) tensor([606.9050, 445.5544])\n",
      "tensor([645.2548, 433.3225]) tensor([619.3480, 431.5219])\n",
      "tensor([653.3350, 464.8552]) tensor([597.3972, 446.7994])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 243.8ms\n",
      "Speed: 2.5ms preprocess, 243.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([654.3473, 475.1481]) tensor([651.8637, 458.0964])\n",
      "tensor([603.0428, 465.5427]) tensor([610.6293, 452.9152])\n",
      "tensor([640.4927, 434.4417]) tensor([618.7088, 433.6033])\n",
      "tensor([654.3473, 475.1481]) tensor([603.0428, 465.5427])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 206.3ms\n",
      "Speed: 3.3ms preprocess, 206.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([636.3967, 471.5338]) tensor([637.6439, 455.3542])\n",
      "tensor([617.6276, 471.3723]) tensor([619.2486, 454.6889])\n",
      "tensor([630.9576, 434.4051]) tensor([621.1906, 434.6511])\n",
      "tensor([636.3967, 471.5338]) tensor([617.6276, 471.3723])\n",
      "2\n",
      "\n",
      "0: 384x640 3 persons, 205.0ms\n",
      "Speed: 2.5ms preprocess, 205.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([653.4803, 471.7555]) tensor([647.0887, 456.0809])\n",
      "tensor([591.9205, 459.0168]) tensor([599.8007, 449.1482])\n",
      "tensor([631.6086, 433.5982]) tensor([610.6154, 432.4475])\n",
      "tensor([653.4803, 471.7555]) tensor([591.9205, 459.0168])\n",
      "2\n",
      "\n",
      "0: 384x640 3 persons, 208.1ms\n",
      "Speed: 2.0ms preprocess, 208.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([649.6389, 469.4334]) tensor([644.7891, 455.1971])\n",
      "tensor([590.2089, 456.8699]) tensor([598.6660, 448.4761])\n",
      "tensor([630.3398, 432.3742]) tensor([608.6282, 431.4175])\n",
      "tensor([649.6389, 469.4334]) tensor([590.2089, 456.8699])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 207.7ms\n",
      "Speed: 2.0ms preprocess, 207.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([642.8770, 467.2202]) tensor([640.9030, 453.2763])\n",
      "tensor([594.1639, 466.4158]) tensor([600.3943, 453.0910])\n",
      "tensor([628.0558, 431.2742]) tensor([606.0807, 432.2401])\n",
      "tensor([642.8770, 467.2202]) tensor([594.1639, 466.4158])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 203.9ms\n",
      "Speed: 2.0ms preprocess, 203.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([635.3856, 464.0032]) tensor([639.9291, 449.2670])\n",
      "tensor([598.4872, 469.4476]) tensor([601.7945, 454.3885])\n",
      "tensor([627.1849, 429.0392]) tensor([605.2224, 432.3505])\n",
      "tensor([635.3856, 464.0032]) tensor([598.4872, 469.4476])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 205.1ms\n",
      "Speed: 2.0ms preprocess, 205.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([642.5377, 465.2354]) tensor([639.8384, 453.1560])\n",
      "tensor([593.0367, 461.6185]) tensor([598.9312, 451.2239])\n",
      "tensor([623.6509, 432.3197]) tensor([604.4752, 432.6076])\n",
      "tensor([642.5377, 465.2354]) tensor([593.0367, 461.6185])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 212.6ms\n",
      "Speed: 3.0ms preprocess, 212.6ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([600.6822, 469.8372]) tensor([606.3256, 453.4701])\n",
      "tensor([636.1569, 466.1040]) tensor([629.5705, 452.0157])\n",
      "tensor([609.3341, 433.5263]) tensor([613.4234, 434.3991])\n",
      "tensor([600.6822, 469.8372]) tensor([636.1569, 466.1040])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 222.8ms\n",
      "Speed: 2.0ms preprocess, 222.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([627.2294, 477.6948]) tensor([629.1112, 459.0235])\n",
      "tensor([594.9186, 483.3490]) tensor([599.3354, 464.2758])\n",
      "tensor([619.2774, 436.6663]) tensor([598.3455, 439.3101])\n",
      "tensor([627.2294, 477.6948]) tensor([594.9186, 483.3490])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 219.5ms\n",
      "Speed: 1.5ms preprocess, 219.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([628.0153, 479.3787]) tensor([630.7759, 461.6444])\n",
      "tensor([591.4131, 491.0820]) tensor([596.8955, 470.4796])\n",
      "tensor([618.1539, 441.6169]) tensor([596.2752, 445.3921])\n",
      "tensor([628.0153, 479.3787]) tensor([591.4131, 491.0820])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 250.2ms\n",
      "Speed: 2.0ms preprocess, 250.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([636.3638, 458.1523]) tensor([634.7496, 456.7384])\n",
      "tensor([587.8174, 458.0631]) tensor([591.9272, 459.9545])\n",
      "tensor([613.7913, 443.8842]) tensor([591.5784, 446.3996])\n",
      "tensor([636.3638, 458.1523]) tensor([587.8174, 458.0631])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 217.8ms\n",
      "Speed: 2.0ms preprocess, 217.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([630.4200, 443.6901]) tensor([627.6965, 450.4180])\n",
      "tensor([590.4619, 443.6039]) tensor([590.7452, 454.1620])\n",
      "1\n",
      "tensor([603.3057, 443.5969]) tensor([586.0680, 446.5590])\n",
      "tensor([630.4200, 443.6901]) tensor([590.4619, 443.6039])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 193.9ms\n",
      "Speed: 1.0ms preprocess, 193.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([628.1727, 451.0865]) tensor([622.1535, 451.9760])\n",
      "tensor([582.2300, 451.3282]) tensor([576.7951, 457.0609])\n",
      "1\n",
      "tensor([595.4042, 445.0078]) tensor([576.0977, 448.8511])\n",
      "tensor([628.1727, 451.0865]) tensor([582.2300, 451.3282])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 203.2ms\n",
      "Speed: 2.0ms preprocess, 203.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([621.3860, 444.8890]) tensor([618.2763, 450.3196])\n",
      "tensor([568.2849, 475.6653]) tensor([570.5930, 469.2012])\n",
      "tensor([591.8092, 445.2906]) tensor([572.3540, 451.6498])\n",
      "tensor([621.3860, 444.8890]) tensor([568.2849, 475.6653])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 205.2ms\n",
      "Speed: 2.0ms preprocess, 205.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([621.2231, 438.7906]) tensor([616.0127, 448.6822])\n",
      "tensor([565.0131, 469.6951]) tensor([566.7475, 468.4720])\n",
      "tensor([588.5297, 446.0409]) tensor([568.0058, 453.1554])\n",
      "tensor([621.2231, 438.7906]) tensor([565.0131, 469.6951])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 204.4ms\n",
      "Speed: 2.1ms preprocess, 204.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([613.8038, 434.8715]) tensor([610.3676, 446.6579])\n",
      "tensor([565.0242, 460.7040]) tensor([560.3224, 465.7498])\n",
      "1\n",
      "tensor([585.5080, 446.2539]) tensor([562.7776, 454.0706])\n",
      "tensor([613.8038, 434.8715]) tensor([565.0242, 460.7040])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 227.3ms\n",
      "Speed: 3.1ms preprocess, 227.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([612.5190, 432.7202]) tensor([605.4894, 447.0249])\n",
      "tensor([559.8130, 457.6729]) tensor([558.4892, 463.1856])\n",
      "1\n",
      "tensor([579.0392, 447.0018]) tensor([561.9738, 453.0962])\n",
      "tensor([612.5190, 432.7202]) tensor([559.8130, 457.6729])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 246.9ms\n",
      "Speed: 2.0ms preprocess, 246.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([605.0519, 433.9137]) tensor([601.4651, 447.4120])\n",
      "tensor([558.8956, 453.5090]) tensor([556.0408, 461.6243])\n",
      "1\n",
      "tensor([577.7229, 449.1347]) tensor([559.2872, 454.2782])\n",
      "tensor([605.0519, 433.9137]) tensor([558.8956, 453.5090])\n",
      "2\n",
      "\n",
      "0: 384x640 3 persons, 234.9ms\n",
      "Speed: 2.1ms preprocess, 234.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([613.0564, 429.1638]) tensor([604.5673, 444.2182])\n",
      "tensor([563.5228, 451.2097]) tensor([557.6342, 459.7487])\n",
      "1\n",
      "tensor([575.5265, 451.1821]) tensor([557.3575, 456.7614])\n",
      "tensor([613.0564, 429.1638]) tensor([563.5228, 451.2097])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 229.8ms\n",
      "Speed: 2.0ms preprocess, 229.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([612.0497, 425.4742]) tensor([602.9029, 441.0511])\n",
      "tensor([569.1221, 444.4017]) tensor([561.7312, 454.4107])\n",
      "1\n",
      "tensor([570.3354, 455.6854]) tensor([557.4641, 460.7791])\n",
      "tensor([612.0497, 425.4742]) tensor([569.1221, 444.4017])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 207.1ms\n",
      "Speed: 1.6ms preprocess, 207.1ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([619.2125, 427.4091]) tensor([599.0329, 442.9397])\n",
      "tensor([565.4385, 434.4829]) tensor([554.3633, 453.4205])\n",
      "1\n",
      "tensor([563.6667, 459.1400]) tensor([552.5960, 465.7622])\n",
      "tensor([619.2125, 427.4091]) tensor([565.4385, 434.4829])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 209.3ms\n",
      "Speed: 2.0ms preprocess, 209.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([535.8455, 456.7314]) tensor([535.6750, 463.4142])\n",
      "tensor([607.0970, 431.6300]) tensor([592.5817, 442.8083])\n",
      "1\n",
      "tensor([546.7105, 465.4590]) tensor([563.1990, 457.5440])\n",
      "tensor([535.8455, 456.7314]) tensor([607.0970, 431.6300])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 202.1ms\n",
      "Speed: 2.0ms preprocess, 202.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([593.8629, 308.4690]) tensor([588.6006, 294.1054])\n",
      "tensor([617.2208, 305.6803]) tensor([618.8389, 291.2955])\n",
      "tensor([592.9720, 276.8136]) tensor([613.8129, 275.5299])\n",
      "tensor([593.8629, 308.4690]) tensor([617.2208, 305.6803])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 226.2ms\n",
      "Speed: 3.5ms preprocess, 226.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([593.2905, 309.1911]) tensor([589.7441, 293.4863])\n",
      "tensor([620.7285, 306.3327]) tensor([622.7333, 290.3201])\n",
      "tensor([594.6492, 276.1025]) tensor([616.6078, 274.4289])\n",
      "tensor([593.2905, 309.1911]) tensor([620.7285, 306.3327])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 217.0ms\n",
      "Speed: 3.0ms preprocess, 217.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([596.0526, 307.5228]) tensor([592.0905, 292.8259])\n",
      "tensor([622.7584, 305.2456]) tensor([626.4495, 289.9044])\n",
      "tensor([596.9586, 275.0798]) tensor([619.8066, 273.4557])\n",
      "tensor([596.0526, 307.5228]) tensor([622.7584, 305.2456])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 273.0ms\n",
      "Speed: 3.0ms preprocess, 273.0ms inference, 1.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([596.8939, 307.6937]) tensor([593.9937, 292.8390])\n",
      "tensor([623.2191, 305.7629]) tensor([627.6486, 290.2690])\n",
      "tensor([599.0639, 274.9350]) tensor([621.4117, 273.3938])\n",
      "tensor([596.8939, 307.6937]) tensor([623.2191, 305.7629])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 219.2ms\n",
      "Speed: 2.0ms preprocess, 219.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([543.5175, 459.0657]) tensor([549.8094, 470.4072])\n",
      "tensor([521.7239, 460.9176]) tensor([523.1271, 473.4787])\n",
      "1\n",
      "tensor([538.1948, 480.2416]) tensor([527.3762, 482.3145])\n",
      "tensor([543.5175, 459.0657]) tensor([521.7239, 460.9176])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 275.6ms\n",
      "Speed: 3.0ms preprocess, 275.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([540.0620, 455.2869]) tensor([546.9760, 466.9759])\n",
      "tensor([518.2938, 455.8041]) tensor([518.1003, 468.4870])\n",
      "1\n",
      "tensor([538.2194, 480.8387]) tensor([526.2191, 482.2318])\n",
      "tensor([540.0620, 455.2869]) tensor([518.2938, 455.8041])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 283.2ms\n",
      "Speed: 2.0ms preprocess, 283.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([541.8839, 447.0676]) tensor([544.9933, 465.3263])\n",
      "tensor([517.7898, 461.0773]) tensor([514.1474, 475.0047])\n",
      "1\n",
      "tensor([530.7668, 474.2388]) tensor([516.9648, 478.4282])\n",
      "tensor([541.8839, 447.0676]) tensor([517.7898, 461.0773])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 271.9ms\n",
      "Speed: 2.0ms preprocess, 271.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([537.5145, 454.7465]) tensor([539.8627, 471.3312])\n",
      "tensor([510.9193, 457.4430]) tensor([506.0341, 471.8012])\n",
      "1\n",
      "tensor([536.1180, 469.9292]) tensor([518.1481, 469.8321])\n",
      "tensor([537.5145, 454.7465]) tensor([510.9193, 457.4430])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 247.8ms\n",
      "Speed: 2.5ms preprocess, 247.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([519.7638, 434.2097]) tensor([529.1046, 452.8813])\n",
      "tensor([506.9308, 446.1414]) tensor([504.6531, 463.8015])\n",
      "1\n",
      "tensor([521.8428, 470.9329]) tensor([508.1980, 476.4753])\n",
      "tensor([519.7638, 434.2097]) tensor([506.9308, 446.1414])\n",
      "\n",
      "0: 384x640 1 person, 246.1ms\n",
      "Speed: 2.1ms preprocess, 246.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([521.0886, 427.7109]) tensor([527.3671, 454.4832])\n",
      "tensor([507.3796, 436.0590]) tensor([504.9692, 460.4827])\n",
      "1\n",
      "tensor([518.1790, 473.4417]) tensor([507.8594, 477.5087])\n",
      "tensor([521.0886, 427.7109]) tensor([507.3796, 436.0590])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 202.7ms\n",
      "Speed: 2.0ms preprocess, 202.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([502.8119, 454.2520]) tensor([518.0234, 467.6197])\n",
      "tensor([494.1256, 455.1229]) tensor([499.3987, 471.3624])\n",
      "1\n",
      "tensor([521.2874, 478.5971]) tensor([507.2476, 481.6851])\n",
      "tensor([502.8119, 454.2520]) tensor([494.1256, 455.1229])\n",
      "\n",
      "0: 384x640 1 person, 221.1ms\n",
      "Speed: 0.0ms preprocess, 221.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([505.8333, 460.6589]) tensor([513.9791, 472.1361])\n",
      "tensor([505.9336, 459.6449]) tensor([503.4448, 472.4286])\n",
      "1\n",
      "tensor([507.3988, 485.1201]) tensor([500.3961, 485.4047])\n",
      "tensor([505.8333, 460.6589]) tensor([505.9336, 459.6449])\n",
      "\n",
      "0: 384x640 1 person, 256.5ms\n",
      "Speed: 2.2ms preprocess, 256.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([504.7320, 462.8833]) tensor([510.5307, 474.0746])\n",
      "tensor([506.6758, 460.5462]) tensor([502.3998, 473.8522])\n",
      "1\n",
      "tensor([503.1139, 488.8924]) tensor([495.7790, 488.9562])\n",
      "tensor([504.7320, 462.8833]) tensor([506.6758, 460.5462])\n",
      "\n",
      "0: 384x640 1 person, 218.1ms\n",
      "Speed: 3.0ms preprocess, 218.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([495.2478, 484.8802]) tensor([505.0131, 491.5974])\n",
      "tensor([485.0402, 490.6910]) tensor([488.7674, 496.7955])\n",
      "1\n",
      "tensor([503.4579, 490.3893]) tensor([491.3656, 493.0491])\n",
      "tensor([495.2478, 484.8802]) tensor([485.0402, 490.6910])\n",
      "\n",
      "0: 384x640 1 person, 264.5ms\n",
      "Speed: 2.0ms preprocess, 264.5ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([507.9910, 488.5820]) tensor([520.0735, 501.3771])\n",
      "tensor([478.3224, 502.1847]) tensor([476.0840, 510.1606])\n",
      "1\n",
      "tensor([507.3910, 499.6771]) tensor([483.1121, 503.1701])\n",
      "tensor([507.9910, 488.5820]) tensor([478.3224, 502.1847])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 257.0ms\n",
      "Speed: 1.9ms preprocess, 257.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([512.9105, 499.2532]) tensor([521.5081, 510.6902])\n",
      "tensor([475.1298, 525.8162]) tensor([470.0464, 526.6821])\n",
      "1\n",
      "tensor([505.4663, 504.2293]) tensor([476.4211, 509.6357])\n",
      "tensor([512.9105, 499.2532]) tensor([475.1298, 525.8162])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 213.2ms\n",
      "Speed: 2.0ms preprocess, 213.2ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([516.8210, 543.3241]) tensor([519.9958, 533.3897])\n",
      "tensor([470.0284, 547.8799]) tensor([473.4997, 537.6776])\n",
      "tensor([507.1054, 512.9018]) tensor([478.0084, 516.0337])\n",
      "tensor([516.8210, 543.3241]) tensor([470.0284, 547.8799])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 223.2ms\n",
      "Speed: 1.9ms preprocess, 223.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([515.8280, 542.4406]) tensor([521.0679, 532.1860])\n",
      "tensor([471.0189, 545.9032]) tensor([471.9188, 534.8255])\n",
      "tensor([508.5659, 513.1446]) tensor([477.9654, 515.4659])\n",
      "tensor([515.8280, 542.4406]) tensor([471.0189, 545.9032])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 228.1ms\n",
      "Speed: 3.0ms preprocess, 228.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([477.8058, 542.5739]) tensor([484.8794, 529.8446])\n",
      "tensor([506.4196, 544.3499]) tensor([508.7033, 530.2599])\n",
      "tensor([489.2860, 510.7156]) tensor([500.5359, 510.3964])\n",
      "tensor([477.8058, 542.5739]) tensor([506.4196, 544.3499])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 211.6ms\n",
      "Speed: 2.0ms preprocess, 211.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([491.2032, 523.2643]) tensor([497.8662, 520.7410])\n",
      "tensor([497.8270, 526.1835]) tensor([501.6787, 524.0760])\n",
      "tensor([501.3637, 504.9146]) tensor([500.1754, 506.3774])\n",
      "tensor([491.2032, 523.2643]) tensor([497.8270, 526.1835])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 212.0ms\n",
      "Speed: 2.0ms preprocess, 212.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([487.2418, 521.5339]) tensor([486.3705, 518.8160])\n",
      "tensor([523.4522, 520.9967]) tensor([526.6104, 516.2294])\n",
      "tensor([489.9546, 501.3204]) tensor([513.7595, 499.4148])\n",
      "tensor([487.2418, 521.5339]) tensor([523.4522, 520.9967])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 233.8ms\n",
      "Speed: 3.1ms preprocess, 233.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([512.8816, 508.9850]) tensor([518.6876, 508.7606])\n",
      "tensor([501.9775, 514.1440]) tensor([504.8602, 513.4350])\n",
      "tensor([512.1090, 494.0679]) tensor([503.3619, 496.3349])\n",
      "tensor([512.8816, 508.9850]) tensor([501.9775, 514.1440])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 203.0ms\n",
      "Speed: 3.0ms preprocess, 203.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([530.8910, 507.0009]) tensor([536.8123, 505.3223])\n",
      "tensor([481.5327, 514.9706]) tensor([492.0873, 509.6083])\n",
      "tensor([523.5293, 488.4861]) tensor([501.7982, 489.7446])\n",
      "tensor([530.8910, 507.0009]) tensor([481.5327, 514.9706])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 244.6ms\n",
      "Speed: 2.0ms preprocess, 244.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([534.0123, 506.7260]) tensor([540.8010, 504.6769])\n",
      "tensor([485.0169, 511.2842]) tensor([494.2348, 507.8692])\n",
      "tensor([528.0753, 486.4884]) tensor([503.8969, 487.8119])\n",
      "tensor([534.0123, 506.7260]) tensor([485.0169, 511.2842])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 236.3ms\n",
      "Speed: 3.1ms preprocess, 236.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([540.4349, 504.5603]) tensor([542.8791, 503.0572])\n",
      "tensor([492.1443, 505.6453]) tensor([496.5258, 505.4265])\n",
      "tensor([530.9284, 485.0337]) tensor([505.0163, 487.2269])\n",
      "tensor([540.4349, 504.5603]) tensor([492.1443, 505.6453])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 200.0ms\n",
      "Speed: 2.0ms preprocess, 200.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([537.3317, 504.6417]) tensor([542.7490, 502.5706])\n",
      "tensor([496.8879, 504.5769]) tensor([501.3894, 504.3352])\n",
      "tensor([534.0201, 483.8509]) tensor([510.1697, 486.0595])\n",
      "tensor([537.3317, 504.6417]) tensor([496.8879, 504.5769])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 214.3ms\n",
      "Speed: 3.0ms preprocess, 214.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([0., 0.]) tensor([543.0183, 501.4184])\n",
      "tensor([502.7327, 506.2548]) tensor([506.1985, 504.3732])\n",
      "tensor([537.3760, 484.0522]) tensor([515.3588, 486.1156])\n",
      "tensor([0., 0.]) tensor([502.7327, 506.2548])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 197.3ms\n",
      "Speed: 2.0ms preprocess, 197.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([541.4064, 503.3702]) tensor([549.0438, 502.3163])\n",
      "tensor([511.1554, 508.4472]) tensor([510.5227, 506.2217])\n",
      "tensor([542.0854, 484.0750]) tensor([518.5993, 486.0757])\n",
      "tensor([541.4064, 503.3702]) tensor([511.1554, 508.4472])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 198.0ms\n",
      "Speed: 2.5ms preprocess, 198.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([554.3294, 503.6434]) tensor([557.6818, 498.9383])\n",
      "tensor([519.7303, 508.4736]) tensor([518.9499, 503.4984])\n",
      "tensor([544.8407, 481.4908]) tensor([523.9692, 483.5812])\n",
      "tensor([554.3294, 503.6434]) tensor([519.7303, 508.4736])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 248.7ms\n",
      "Speed: 2.0ms preprocess, 248.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([553.6694, 498.2009]) tensor([559.7137, 496.2465])\n",
      "tensor([523.7023, 501.8849]) tensor([523.0340, 499.3315])\n",
      "tensor([551.4831, 480.2834]) tensor([528.6473, 481.6615])\n",
      "tensor([553.6694, 498.2009]) tensor([523.7023, 501.8849])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 228.2ms\n",
      "Speed: 2.0ms preprocess, 228.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([564.6015, 498.2416]) tensor([569.8282, 493.5484])\n",
      "tensor([527.5826, 504.4927]) tensor([528.8239, 497.9642])\n",
      "tensor([558.1293, 475.2125]) tensor([532.7563, 476.7452])\n",
      "tensor([564.6015, 498.2416]) tensor([527.5826, 504.4927])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 255.5ms\n",
      "Speed: 1.5ms preprocess, 255.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([575.2621, 493.3448]) tensor([577.6166, 489.5589])\n",
      "tensor([538.0241, 502.5900]) tensor([537.4274, 495.6796])\n",
      "tensor([562.6479, 472.2301]) tensor([539.3093, 474.9457])\n",
      "tensor([575.2621, 493.3448]) tensor([538.0241, 502.5900])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 229.7ms\n",
      "Speed: 2.0ms preprocess, 229.7ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([576.6966, 495.8113]) tensor([577.7328, 486.7089])\n",
      "tensor([537.4899, 500.3317]) tensor([538.8688, 489.8333])\n",
      "tensor([566.5874, 467.2912]) tensor([541.4333, 469.3957])\n",
      "tensor([576.6966, 495.8113]) tensor([537.4899, 500.3317])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 220.7ms\n",
      "Speed: 2.6ms preprocess, 220.7ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([578.6992, 488.9287]) tensor([584.2650, 479.7096])\n",
      "tensor([540.3190, 491.6445]) tensor([542.8411, 483.2174])\n",
      "tensor([572.4404, 460.3839]) tensor([548.5742, 462.4337])\n",
      "tensor([578.6992, 488.9287]) tensor([540.3190, 491.6445])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 215.1ms\n",
      "Speed: 2.0ms preprocess, 215.1ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([577.3434, 480.0753]) tensor([584.3521, 473.0433])\n",
      "tensor([542.5726, 488.9168]) tensor([545.7351, 479.4128])\n",
      "tensor([571.5865, 456.3804]) tensor([551.6072, 458.5638])\n",
      "tensor([577.3434, 480.0753]) tensor([542.5726, 488.9168])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 220.3ms\n",
      "Speed: 2.0ms preprocess, 220.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([585.8278, 494.7410]) tensor([587.5865, 478.5168])\n",
      "tensor([542.6692, 494.3224]) tensor([543.5025, 480.4440])\n",
      "tensor([577.5117, 456.4924]) tensor([549.8322, 458.4258])\n",
      "tensor([585.8278, 494.7410]) tensor([542.6692, 494.3224])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 249.2ms\n",
      "Speed: 2.0ms preprocess, 249.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([590.5366, 489.7949]) tensor([592.7387, 478.5788])\n",
      "tensor([548.0374, 491.4262]) tensor([548.5164, 478.5634])\n",
      "tensor([578.8481, 458.0078]) tensor([553.0966, 458.5349])\n",
      "tensor([590.5366, 489.7949]) tensor([548.0374, 491.4262])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 260.4ms\n",
      "Speed: 2.0ms preprocess, 260.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([593.8277, 490.7010]) tensor([594.6354, 478.5818])\n",
      "tensor([547.6057, 495.3076]) tensor([549.3403, 482.9809])\n",
      "tensor([582.5715, 459.1780]) tensor([555.0758, 461.4219])\n",
      "tensor([593.8277, 490.7010]) tensor([547.6057, 495.3076])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 217.4ms\n",
      "Speed: 2.2ms preprocess, 217.4ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([605.5360, 504.0021]) tensor([599.8060, 485.0841])\n",
      "tensor([552.9184, 496.5616]) tensor([556.1571, 483.3742])\n",
      "tensor([585.3400, 461.6341]) tensor([558.9651, 462.6961])\n",
      "tensor([605.5360, 504.0021]) tensor([552.9184, 496.5616])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 213.7ms\n",
      "Speed: 2.5ms preprocess, 213.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([610.1088, 508.0368]) tensor([604.7517, 485.9172])\n",
      "tensor([553.0258, 509.8703]) tensor([555.6545, 488.6896])\n",
      "tensor([588.0822, 463.3982]) tensor([561.8794, 465.1305])\n",
      "tensor([610.1088, 508.0368]) tensor([553.0258, 509.8703])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 215.1ms\n",
      "Speed: 2.5ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([615.3312, 512.5347]) tensor([606.2694, 489.3234])\n",
      "tensor([555.9298, 521.1049]) tensor([557.7448, 494.9811])\n",
      "tensor([588.7253, 467.8384]) tensor([562.5045, 469.9500])\n",
      "tensor([615.3312, 512.5347]) tensor([555.9298, 521.1049])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 218.1ms\n",
      "Speed: 2.0ms preprocess, 218.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([621.8334, 522.5208]) tensor([610.7791, 495.8508])\n",
      "tensor([556.5665, 529.0312]) tensor([554.0764, 501.4169])\n",
      "tensor([591.9053, 472.1041]) tensor([559.1637, 475.4719])\n",
      "tensor([621.8334, 522.5208]) tensor([556.5665, 529.0312])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 215.1ms\n",
      "Speed: 2.0ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([619.3572, 519.4649]) tensor([607.4521, 494.2051])\n",
      "tensor([555.2014, 522.1991]) tensor([552.5651, 497.3108])\n",
      "tensor([587.9866, 470.3274]) tensor([557.7176, 472.8008])\n",
      "tensor([619.3572, 519.4649]) tensor([555.2014, 522.1991])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 207.2ms\n",
      "Speed: 2.0ms preprocess, 207.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([603.7123, 503.1152]) tensor([600.8330, 485.8444])\n",
      "tensor([558.9670, 511.0998]) tensor([551.9039, 493.3109])\n",
      "tensor([582.5673, 467.2064]) tensor([554.8530, 471.1116])\n",
      "tensor([603.7123, 503.1152]) tensor([558.9670, 511.0998])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 247.9ms\n",
      "Speed: 3.0ms preprocess, 247.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([593.8188, 489.3801]) tensor([589.6266, 482.3829])\n",
      "tensor([557.7715, 494.4523]) tensor([552.0559, 486.8714])\n",
      "tensor([575.2216, 465.7725]) tensor([552.6585, 468.0403])\n",
      "tensor([593.8188, 489.3801]) tensor([557.7715, 494.4523])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 221.6ms\n",
      "Speed: 3.0ms preprocess, 221.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([585.9301, 483.8946]) tensor([583.7377, 475.6046])\n",
      "tensor([554.6397, 492.2551]) tensor([550.2474, 481.8783])\n",
      "tensor([567.6716, 460.2604]) tensor([550.2807, 462.6407])\n",
      "tensor([585.9301, 483.8946]) tensor([554.6397, 492.2551])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 205.4ms\n",
      "Speed: 0.5ms preprocess, 205.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([586.1991, 480.6425]) tensor([580.7568, 475.0335])\n",
      "tensor([542.7570, 488.1628]) tensor([537.5388, 481.2840])\n",
      "tensor([565.4432, 460.4722]) tensor([541.3468, 463.3530])\n",
      "tensor([586.1991, 480.6425]) tensor([542.7570, 488.1628])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 218.6ms\n",
      "Speed: 2.0ms preprocess, 218.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([585.0694, 469.1496]) tensor([577.7035, 472.5338])\n",
      "tensor([541.8048, 474.8582]) tensor([532.5120, 478.9215])\n",
      "1\n",
      "tensor([560.9077, 459.9715]) tensor([536.1895, 463.2737])\n",
      "tensor([585.0694, 469.1496]) tensor([541.8048, 474.8582])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 204.8ms\n",
      "Speed: 3.0ms preprocess, 204.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([584.5007, 462.0064]) tensor([575.8369, 466.4427])\n",
      "tensor([532.0930, 474.8716]) tensor([525.3275, 476.2673])\n",
      "1\n",
      "tensor([558.0132, 455.3135]) tensor([531.4365, 459.8598])\n",
      "tensor([584.5007, 462.0064]) tensor([532.0930, 474.8716])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 211.0ms\n",
      "Speed: 2.2ms preprocess, 211.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([585.3513, 461.5362]) tensor([573.0676, 466.3794])\n",
      "tensor([537.9235, 464.0342]) tensor([527.4048, 471.3299])\n",
      "1\n",
      "tensor([552.5044, 456.3564]) tensor([529.0878, 459.6874])\n",
      "tensor([585.3513, 461.5362]) tensor([537.9235, 464.0342])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 229.5ms\n",
      "Speed: 2.0ms preprocess, 229.5ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([579.1265, 462.0063]) tensor([567.4553, 466.6295])\n",
      "tensor([537.8323, 463.8603]) tensor([527.5930, 471.2720])\n",
      "1\n",
      "tensor([547.9188, 457.2556]) tensor([526.5941, 459.6315])\n",
      "tensor([579.1265, 462.0063]) tensor([537.8323, 463.8603])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 218.0ms\n",
      "Speed: 3.0ms preprocess, 218.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([571.7517, 460.7648]) tensor([560.7645, 467.1268])\n",
      "tensor([552.5215, 463.4008]) tensor([540.2497, 471.2203])\n",
      "1\n",
      "tensor([540.5449, 459.0019]) tensor([529.6610, 460.5086])\n",
      "tensor([571.7517, 460.7648]) tensor([552.5215, 463.4008])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 197.6ms\n",
      "Speed: 2.5ms preprocess, 197.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([562.5636, 461.1672]) tensor([553.3167, 470.8615])\n",
      "tensor([542.1246, 467.1183]) tensor([531.1598, 476.2727])\n",
      "1\n",
      "tensor([537.8351, 462.9745]) tensor([525.4991, 464.7009])\n",
      "tensor([562.5636, 461.1672]) tensor([542.1246, 467.1183])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 208.2ms\n",
      "Speed: 2.0ms preprocess, 208.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([555.5620, 469.7945]) tensor([548.5803, 476.4886])\n",
      "tensor([543.9633, 474.1436]) tensor([533.0674, 481.4565])\n",
      "1\n",
      "tensor([534.1525, 466.4598]) tensor([523.5635, 468.3754])\n",
      "tensor([555.5620, 469.7945]) tensor([543.9633, 474.1436])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 206.9ms\n",
      "Speed: 2.0ms preprocess, 206.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([553.8732, 468.7162]) tensor([547.0930, 479.0454])\n",
      "tensor([543.7883, 472.5536]) tensor([533.3967, 482.8819])\n",
      "1\n",
      "tensor([530.2327, 470.4001]) tensor([520.9152, 471.6864])\n",
      "tensor([553.8732, 468.7162]) tensor([543.7883, 472.5536])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 246.4ms\n",
      "Speed: 3.0ms preprocess, 246.4ms inference, 3.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([542.3994, 470.7202]) tensor([537.6309, 482.9785])\n",
      "tensor([531.7305, 470.3983]) tensor([523.5297, 484.1960])\n",
      "1\n",
      "tensor([526.3171, 473.6968]) tensor([517.9590, 474.6410])\n",
      "tensor([542.3994, 470.7202]) tensor([531.7305, 470.3983])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 218.9ms\n",
      "Speed: 3.0ms preprocess, 218.9ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([538.0728, 476.8300]) tensor([528.3759, 487.2321])\n",
      "tensor([534.8071, 476.3847]) tensor([527.0930, 484.7505])\n",
      "1\n",
      "tensor([519.1640, 478.0849]) tensor([518.3076, 476.4914])\n",
      "tensor([538.0728, 476.8300]) tensor([534.8071, 476.3847])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 219.0ms\n",
      "Speed: 1.6ms preprocess, 219.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([535.7471, 480.4857]) tensor([523.9554, 489.8000])\n",
      "tensor([534.0735, 479.9526]) tensor([528.2347, 486.7995])\n",
      "1\n",
      "tensor([514.7844, 479.8648]) tensor([519.4921, 478.2306])\n",
      "tensor([535.7471, 480.4857]) tensor([534.0735, 479.9526])\n",
      "\n",
      "0: 384x640 1 person, 202.0ms\n",
      "Speed: 2.3ms preprocess, 202.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([0., 0.]) tensor([0., 0.])\n",
      "tensor([518.1904, 485.1772]) tensor([522.6077, 491.4002])\n",
      "tensor([514.3066, 481.7562]) tensor([516.0742, 482.7599])\n",
      "tensor([0., 0.]) tensor([518.1904, 485.1772])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 206.9ms\n",
      "Speed: 3.0ms preprocess, 206.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([499.7397, 464.0015]) tensor([502.3838, 480.6941])\n",
      "tensor([506.6525, 480.7697]) tensor([518.9020, 489.2152])\n",
      "1\n",
      "tensor([512.8465, 484.5468]) tensor([519.8652, 486.8862])\n",
      "tensor([499.7397, 464.0015]) tensor([506.6525, 480.7697])\n",
      "\n",
      "0: 384x640 1 person, 228.2ms\n",
      "Speed: 2.0ms preprocess, 228.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([488.8130, 462.1572]) tensor([496.1261, 478.4993])\n",
      "tensor([497.9254, 477.6533]) tensor([512.7667, 488.8889])\n",
      "1\n",
      "tensor([509.0431, 489.1297]) tensor([518.5114, 492.4296])\n",
      "tensor([488.8130, 462.1572]) tensor([497.9254, 477.6533])\n",
      "\n",
      "0: 384x640 1 person, 223.3ms\n",
      "Speed: 2.0ms preprocess, 223.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([506.9907, 498.3538]) tensor([509.5044, 503.5000])\n",
      "tensor([507.5661, 505.9016]) tensor([513.0422, 508.0771])\n",
      "1\n",
      "tensor([511.5244, 490.9191]) tensor([512.8382, 492.5811])\n",
      "tensor([506.9907, 498.3538]) tensor([507.5661, 505.9016])\n",
      "\n",
      "0: 384x640 1 person, 198.3ms\n",
      "Speed: 2.0ms preprocess, 198.3ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([490.6281, 463.4585]) tensor([491.5204, 481.1151])\n",
      "tensor([500.7467, 478.4890]) tensor([512.5583, 489.4637])\n",
      "1\n",
      "tensor([503.2133, 487.6699]) tensor([514.7592, 490.0707])\n",
      "tensor([490.6281, 463.4585]) tensor([500.7467, 478.4890])\n",
      "\n",
      "0: 384x640 1 person, 206.7ms\n",
      "Speed: 2.0ms preprocess, 206.7ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([490.1789, 464.0945]) tensor([494.7584, 477.2091])\n",
      "tensor([494.9654, 471.5440]) tensor([504.7093, 482.7189])\n",
      "1\n",
      "tensor([503.1282, 487.1524]) tensor([509.0857, 489.1298])\n",
      "tensor([490.1789, 464.0945]) tensor([494.9654, 471.5440])\n",
      "\n",
      "0: 384x640 1 person, 207.7ms\n",
      "Speed: 2.0ms preprocess, 207.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([498.6365, 464.7294]) tensor([501.5833, 477.6698])\n",
      "tensor([500.9229, 470.7789]) tensor([508.0782, 481.4838])\n",
      "1\n",
      "tensor([500.7033, 484.1370]) tensor([505.8897, 485.3131])\n",
      "tensor([498.6365, 464.7294]) tensor([500.9229, 470.7789])\n",
      "\n",
      "0: 384x640 1 person, 217.7ms\n",
      "Speed: 2.5ms preprocess, 217.7ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([505.9688, 465.0431]) tensor([507.4707, 474.6743])\n",
      "tensor([502.3968, 467.1844]) tensor([504.5671, 475.6387])\n",
      "1\n",
      "tensor([500.2632, 480.9041]) tensor([500.7146, 480.9103])\n",
      "tensor([505.9688, 465.0431]) tensor([502.3968, 467.1844])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 214.8ms\n",
      "Speed: 2.5ms preprocess, 214.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([505.6029, 456.2480]) tensor([513.0251, 469.2223])\n",
      "tensor([488.8893, 455.5432]) tensor([486.1547, 467.9033])\n",
      "1\n",
      "tensor([511.7490, 481.0474]) tensor([498.7530, 480.0284])\n",
      "tensor([505.6029, 456.2480]) tensor([488.8893, 455.5432])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 202.1ms\n",
      "Speed: 2.0ms preprocess, 202.1ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([523.9562, 435.1312]) tensor([519.9971, 458.9241])\n",
      "tensor([514.8651, 438.5060]) tensor([503.3731, 463.8722])\n",
      "1\n",
      "tensor([499.9419, 478.0782]) tensor([493.7080, 480.8606])\n",
      "tensor([523.9562, 435.1312]) tensor([514.8651, 438.5060])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 201.7ms\n",
      "Speed: 3.0ms preprocess, 201.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([525.7631, 435.7470]) tensor([518.9434, 459.7910])\n",
      "tensor([517.0192, 436.3468]) tensor([500.6275, 464.6651])\n",
      "1\n",
      "tensor([498.2255, 477.6772]) tensor([488.2683, 481.0317])\n",
      "tensor([525.7631, 435.7470]) tensor([517.0192, 436.3468])\n",
      "\n",
      "0: 384x640 1 person, 225.0ms\n",
      "Speed: 1.8ms preprocess, 225.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([532.4886, 442.1174]) tensor([523.4222, 463.4901])\n",
      "tensor([524.0470, 446.2600]) tensor([507.7683, 470.0002])\n",
      "1\n",
      "tensor([496.2347, 478.0031]) tensor([488.0051, 481.3717])\n",
      "tensor([532.4886, 442.1174]) tensor([524.0470, 446.2600])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 227.5ms\n",
      "Speed: 2.0ms preprocess, 227.5ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([526.2499, 456.2392]) tensor([519.3879, 473.7186])\n",
      "tensor([511.4845, 462.2745]) tensor([495.3030, 481.0026])\n",
      "1\n",
      "tensor([495.1445, 481.1747]) tensor([481.9669, 484.6013])\n",
      "tensor([526.2499, 456.2392]) tensor([511.4845, 462.2745])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 230.4ms\n",
      "Speed: 2.0ms preprocess, 230.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([515.6130, 470.1303]) tensor([516.3475, 488.8950])\n",
      "tensor([490.6536, 477.9509]) tensor([478.6950, 496.1556])\n",
      "1\n",
      "tensor([497.0858, 489.3054]) tensor([475.6485, 492.9217])\n",
      "tensor([515.6130, 470.1303]) tensor([490.6536, 477.9509])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 213.0ms\n",
      "Speed: 2.7ms preprocess, 213.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([500.2551, 496.6359]) tensor([509.0996, 508.3401])\n",
      "tensor([483.7550, 501.8736]) tensor([476.7803, 512.7997])\n",
      "1\n",
      "tensor([499.4672, 498.2054]) tensor([476.3445, 500.8571])\n",
      "tensor([500.2551, 496.6359]) tensor([483.7550, 501.8736])\n",
      "\n",
      "0: 384x640 2 persons, 201.1ms\n",
      "Speed: 3.0ms preprocess, 201.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([0., 0.]) tensor([512.5783, 523.0396])\n",
      "tensor([476.3360, 527.2156]) tensor([478.0695, 527.0771])\n",
      "tensor([501.3744, 503.5424]) tensor([476.9066, 506.4088])\n",
      "tensor([0., 0.]) tensor([476.3360, 527.2156])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 243.9ms\n",
      "Speed: 2.0ms preprocess, 243.9ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([503.9453, 539.1498]) tensor([513.1202, 531.3110])\n",
      "tensor([475.5318, 547.9435]) tensor([478.8446, 537.5355])\n",
      "tensor([502.2759, 509.7407]) tensor([478.8765, 512.8512])\n",
      "tensor([503.9453, 539.1498]) tensor([475.5318, 547.9435])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 213.7ms\n",
      "Speed: 3.1ms preprocess, 213.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([505.7506, 540.3608]) tensor([514.5131, 531.6946])\n",
      "tensor([474.8158, 549.1528]) tensor([478.2126, 537.7954])\n",
      "tensor([503.7553, 510.4217]) tensor([479.8839, 513.3633])\n",
      "tensor([505.7506, 540.3608]) tensor([474.8158, 549.1528])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 239.9ms\n",
      "Speed: 1.0ms preprocess, 239.9ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([499.2000, 537.7842]) tensor([510.9496, 530.3207])\n",
      "tensor([477.3549, 540.1601]) tensor([481.8214, 533.2872])\n",
      "tensor([504.7560, 509.3168]) tensor([485.1961, 511.1434])\n",
      "tensor([499.2000, 537.7842]) tensor([477.3549, 540.1601])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 225.9ms\n",
      "Speed: 2.7ms preprocess, 225.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([509.4543, 529.9442]) tensor([516.6888, 525.3170])\n",
      "tensor([484.0751, 535.6088]) tensor([483.2051, 530.2751])\n",
      "tensor([508.3018, 504.8785]) tensor([485.6345, 507.6072])\n",
      "tensor([509.4543, 529.9442]) tensor([484.0751, 535.6088])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 219.7ms\n",
      "Speed: 2.5ms preprocess, 219.7ms inference, 0.9ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([488.5759, 525.6452]) tensor([482.7632, 527.6161])\n",
      "tensor([499.6533, 517.0381]) tensor([507.3047, 519.0203])\n",
      "1\n",
      "tensor([489.8510, 508.7524]) tensor([507.3083, 503.5695])\n",
      "tensor([488.5759, 525.6452]) tensor([499.6533, 517.0381])\n",
      "\n",
      "0: 384x640 2 persons, 215.1ms\n",
      "Speed: 2.2ms preprocess, 215.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([504.0526, 529.7245]) tensor([513.1307, 523.5222])\n",
      "tensor([489.6666, 534.1475]) tensor([490.0197, 526.2678])\n",
      "tensor([512.7280, 502.6329]) tensor([495.3738, 504.5437])\n",
      "tensor([504.0526, 529.7245]) tensor([489.6666, 534.1475])\n",
      "\n",
      "0: 384x640 2 persons, 206.0ms\n",
      "Speed: 2.0ms preprocess, 206.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([511.4117, 530.5298]) tensor([518.2665, 523.4788])\n",
      "tensor([491.8114, 533.3558]) tensor([494.0502, 526.2234])\n",
      "tensor([518.6197, 501.3188]) tensor([498.2102, 503.0863])\n",
      "tensor([511.4117, 530.5298]) tensor([491.8114, 533.3558])\n",
      "\n",
      "0: 384x640 1 person, 201.9ms\n",
      "Speed: 2.0ms preprocess, 201.9ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([527.5301, 528.3554]) tensor([531.7142, 522.9406])\n",
      "tensor([500.0262, 534.4167]) tensor([496.1527, 528.8329])\n",
      "tensor([524.4884, 502.8712]) tensor([498.3350, 505.8516])\n",
      "tensor([527.5301, 528.3554]) tensor([500.0262, 534.4167])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 202.8ms\n",
      "Speed: 2.5ms preprocess, 202.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([531.6744, 531.2472]) tensor([536.5867, 525.6576])\n",
      "tensor([505.2766, 531.6257]) tensor([500.7343, 526.9897])\n",
      "tensor([529.9282, 505.0989]) tensor([504.3279, 507.0080])\n",
      "tensor([531.6744, 531.2472]) tensor([505.2766, 531.6257])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 205.0ms\n",
      "Speed: 2.2ms preprocess, 205.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([539.5412, 532.9982]) tensor([542.1656, 523.6016])\n",
      "tensor([509.3407, 536.0770]) tensor([503.8063, 527.3480])\n",
      "tensor([534.0321, 503.3559]) tensor([507.0991, 506.2403])\n",
      "tensor([539.5412, 532.9982]) tensor([509.3407, 536.0770])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 216.5ms\n",
      "Speed: 2.3ms preprocess, 216.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([0., 0.]) tensor([547.6614, 522.5181])\n",
      "tensor([514.4768, 531.0661]) tensor([516.2469, 522.8695])\n",
      "tensor([540.6061, 501.7073]) tensor([520.0228, 502.2968])\n",
      "tensor([0., 0.]) tensor([514.4768, 531.0661])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 209.7ms\n",
      "Speed: 2.0ms preprocess, 209.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([559.1884, 524.0745]) tensor([561.0367, 515.6741])\n",
      "tensor([516.6335, 523.4140]) tensor([517.1724, 516.8743])\n",
      "tensor([545.9997, 495.9502]) tensor([523.6859, 497.1238])\n",
      "tensor([559.1884, 524.0745]) tensor([516.6335, 523.4140])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 209.8ms\n",
      "Speed: 2.0ms preprocess, 209.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([558.9552, 515.8497]) tensor([562.2546, 509.9382])\n",
      "tensor([515.9806, 513.8736]) tensor([520.5472, 509.4260])\n",
      "tensor([552.6519, 488.7021]) tensor([528.3909, 489.2507])\n",
      "tensor([558.9552, 515.8497]) tensor([515.9806, 513.8736])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 209.4ms\n",
      "Speed: 3.0ms preprocess, 209.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([520.7036, 507.6437]) tensor([521.5590, 502.2765])\n",
      "tensor([570.0832, 506.9887]) tensor([570.3984, 499.3798])\n",
      "tensor([529.7141, 483.9811]) tensor([555.6472, 481.8573])\n",
      "tensor([520.7036, 507.6437]) tensor([570.0832, 506.9887])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 217.7ms\n",
      "Speed: 2.0ms preprocess, 217.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([530.8235, 502.9478]) tensor([539.5818, 496.4604])\n",
      "tensor([559.4571, 507.9760]) tensor([557.0189, 499.8698])\n",
      "tensor([547.2808, 477.5790]) tensor([549.7853, 479.5698])\n",
      "tensor([530.8235, 502.9478]) tensor([559.4571, 507.9760])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 225.9ms\n",
      "Speed: 2.0ms preprocess, 225.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([577.5701, 513.9550]) tensor([578.1101, 498.7790])\n",
      "tensor([522.0384, 503.7899]) tensor([528.5412, 496.8571])\n",
      "tensor([563.1219, 475.7867]) tensor([538.6711, 476.8218])\n",
      "tensor([577.5701, 513.9550]) tensor([522.0384, 503.7899])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 219.3ms\n",
      "Speed: 2.0ms preprocess, 219.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([585.2625, 509.9503]) tensor([579.8235, 495.0708])\n",
      "tensor([529.1864, 500.5823]) tensor([530.6437, 492.7557])\n",
      "tensor([567.5237, 473.4986]) tensor([539.0120, 475.0510])\n",
      "tensor([585.2625, 509.9503]) tensor([529.1864, 500.5823])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 225.0ms\n",
      "Speed: 1.5ms preprocess, 225.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([591.5076, 510.5281]) tensor([585.0327, 496.1785])\n",
      "tensor([535.2433, 499.8391]) tensor([534.4893, 493.3700])\n",
      "tensor([572.4077, 472.8295]) tensor([543.2509, 474.2584])\n",
      "tensor([591.5076, 510.5281]) tensor([535.2433, 499.8391])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 230.0ms\n",
      "Speed: 2.0ms preprocess, 230.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([597.9291, 511.5595]) tensor([592.1864, 496.2737])\n",
      "tensor([537.4698, 500.5557]) tensor([537.8952, 493.4133])\n",
      "tensor([577.9589, 472.8721]) tensor([548.5565, 474.1188])\n",
      "tensor([597.9291, 511.5595]) tensor([537.4698, 500.5557])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 245.3ms\n",
      "Speed: 2.4ms preprocess, 245.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([601.6959, 513.3195]) tensor([596.1401, 497.6257])\n",
      "tensor([537.7431, 506.1125]) tensor([540.9539, 496.8888])\n",
      "tensor([580.0767, 474.7048]) tensor([551.4084, 476.4028])\n",
      "tensor([601.6959, 513.3195]) tensor([537.7431, 506.1125])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 239.8ms\n",
      "Speed: 4.1ms preprocess, 239.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([606.7112, 515.1745]) tensor([601.1677, 500.4096])\n",
      "tensor([537.1003, 493.4691]) tensor([540.9176, 493.5400])\n",
      "tensor([583.8936, 477.1290]) tensor([554.7329, 477.9736])\n",
      "tensor([606.7112, 515.1745]) tensor([537.1003, 493.4691])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 223.5ms\n",
      "Speed: 2.0ms preprocess, 223.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([610.3197, 513.5718]) tensor([605.7203, 499.0404])\n",
      "tensor([537.2756, 487.2795]) tensor([544.4652, 490.1719])\n",
      "tensor([587.9331, 475.6049]) tensor([559.7234, 475.9468])\n",
      "tensor([610.3197, 513.5718]) tensor([537.2756, 487.2795])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 213.5ms\n",
      "Speed: 2.5ms preprocess, 213.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([612.7300, 508.7511]) tensor([607.3512, 495.0048])\n",
      "tensor([528.0447, 473.4365]) tensor([537.9133, 479.5757])\n",
      "tensor([589.8017, 472.2654]) tensor([561.1373, 470.0334])\n",
      "tensor([612.7300, 508.7511]) tensor([528.0447, 473.4365])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 217.5ms\n",
      "Speed: 1.6ms preprocess, 217.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([608.7755, 497.1327]) tensor([603.7501, 487.1562])\n",
      "tensor([527.4487, 467.6080]) tensor([537.8543, 473.4155])\n",
      "tensor([589.1324, 468.3618]) tensor([564.1302, 465.8817])\n",
      "tensor([608.7755, 497.1327]) tensor([527.4487, 467.6080])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 213.6ms\n",
      "Speed: 2.0ms preprocess, 213.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([597.9446, 493.5681]) tensor([603.0948, 483.6382])\n",
      "tensor([520.9293, 464.4333]) tensor([537.2000, 469.6769])\n",
      "tensor([591.7594, 462.3831]) tensor([564.6627, 459.7556])\n",
      "tensor([597.9446, 493.5681]) tensor([520.9293, 464.4333])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 210.2ms\n",
      "Speed: 2.0ms preprocess, 210.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([606.9787, 432.7234]) tensor([608.4311, 452.2163])\n",
      "tensor([521.1016, 463.3409]) tensor([542.4908, 467.0245])\n",
      "1\n",
      "tensor([589.3768, 451.7876]) tensor([566.2339, 454.8959])\n",
      "tensor([606.9787, 432.7234]) tensor([521.1016, 463.3409])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 202.2ms\n",
      "Speed: 2.0ms preprocess, 202.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([619.8220, 424.7320]) tensor([615.2246, 445.9014])\n",
      "tensor([524.6634, 461.1057]) tensor([540.2802, 464.4963])\n",
      "1\n",
      "tensor([590.3799, 446.7975]) tensor([562.8652, 451.7015])\n",
      "tensor([619.8220, 424.7320]) tensor([524.6634, 461.1057])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 201.1ms\n",
      "Speed: 2.0ms preprocess, 201.1ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([621.7642, 428.8545]) tensor([609.5743, 445.6945])\n",
      "tensor([521.1195, 463.6015]) tensor([539.0145, 464.0480])\n",
      "1\n",
      "tensor([587.2496, 441.9617]) tensor([559.4998, 447.6893])\n",
      "tensor([621.7642, 428.8545]) tensor([521.1195, 463.6015])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 208.2ms\n",
      "Speed: 2.0ms preprocess, 208.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([622.2027, 428.6639]) tensor([608.0676, 440.7479])\n",
      "tensor([524.8201, 459.3727]) tensor([536.3812, 458.7863])\n",
      "tensor([584.1616, 434.9094]) tensor([554.2912, 441.2668])\n",
      "tensor([622.2027, 428.6639]) tensor([524.8201, 459.3727])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 210.0ms\n",
      "Speed: 2.0ms preprocess, 210.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([601.8279, 435.8400]) tensor([597.6837, 440.9841])\n",
      "tensor([524.3559, 456.7491]) tensor([542.1224, 451.9805])\n",
      "tensor([576.2601, 431.7762]) tensor([559.0463, 434.8964])\n",
      "tensor([601.8279, 435.8400]) tensor([524.3559, 456.7491])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 244.8ms\n",
      "Speed: 2.0ms preprocess, 244.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([597.7253, 438.8001]) tensor([595.3403, 439.1962])\n",
      "tensor([523.7543, 459.1685]) tensor([541.3702, 450.6746])\n",
      "tensor([573.3638, 428.0518]) tensor([557.6142, 431.5756])\n",
      "tensor([597.7253, 438.8001]) tensor([523.7543, 459.1685])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 215.8ms\n",
      "Speed: 3.0ms preprocess, 215.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([543.6586, 454.7595]) tensor([562.9336, 444.2686])\n",
      "tensor([529.8925, 460.1192]) tensor([547.0388, 449.1628])\n",
      "tensor([564.7678, 427.9153]) tensor([558.9653, 429.4428])\n",
      "tensor([543.6586, 454.7595]) tensor([529.8925, 460.1192])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 200.9ms\n",
      "Speed: 2.0ms preprocess, 200.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([546.4794, 454.6444]) tensor([563.0735, 442.3546])\n",
      "tensor([534.1135, 461.9399]) tensor([549.8604, 447.6561])\n",
      "tensor([563.3400, 425.6558]) tensor([557.4366, 427.2776])\n",
      "tensor([546.4794, 454.6444]) tensor([534.1135, 461.9399])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 207.5ms\n",
      "Speed: 2.0ms preprocess, 207.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([534.5993, 458.1865]) tensor([551.9484, 441.8213])\n",
      "tensor([527.0911, 461.0855]) tensor([547.8434, 445.7199])\n",
      "tensor([559.6027, 423.3950]) tensor([556.3958, 424.7193])\n",
      "tensor([534.5993, 458.1865]) tensor([527.0911, 461.0855])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 226.8ms\n",
      "Speed: 2.0ms preprocess, 226.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([531.4332, 459.9437]) tensor([547.0701, 441.9589])\n",
      "tensor([532.4389, 461.0062]) tensor([549.6013, 445.0302])\n",
      "tensor([554.9778, 421.5696]) tensor([553.4957, 422.9772])\n",
      "tensor([531.4332, 459.9437]) tensor([532.4389, 461.0062])\n",
      "\n",
      "0: 384x640 1 person, 221.1ms\n",
      "Speed: 2.0ms preprocess, 221.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([534.8559, 459.4815]) tensor([546.9501, 440.5931])\n",
      "tensor([533.8842, 462.0863]) tensor([545.4682, 443.7198])\n",
      "tensor([552.7843, 419.8676]) tensor([548.9135, 421.4235])\n",
      "tensor([534.8559, 459.4815]) tensor([533.8842, 462.0863])\n",
      "\n",
      "0: 384x640 1 person, 216.7ms\n",
      "Speed: 1.5ms preprocess, 216.7ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([532.5662, 458.8739]) tensor([544.2946, 440.2223])\n",
      "tensor([532.0746, 461.4008]) tensor([544.1050, 443.0580])\n",
      "tensor([549.7667, 418.7353]) tensor([547.3529, 420.0471])\n",
      "tensor([532.5662, 458.8739]) tensor([532.0746, 461.4008])\n",
      "\n",
      "0: 384x640 1 person, 227.9ms\n",
      "Speed: 2.0ms preprocess, 227.9ms inference, 0.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([532.2891, 457.7975]) tensor([541.9962, 438.4297])\n",
      "tensor([535.1760, 459.9001]) tensor([545.1913, 440.6543])\n",
      "tensor([546.5198, 416.6155]) tensor([545.6888, 417.6176])\n",
      "tensor([532.2891, 457.7975]) tensor([535.1760, 459.9001])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 218.6ms\n",
      "Speed: 3.1ms preprocess, 218.6ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([531.5760, 455.2574]) tensor([539.9199, 435.7711])\n",
      "tensor([535.9187, 456.5209]) tensor([545.0133, 437.2424])\n",
      "tensor([542.5044, 414.8884]) tensor([541.9593, 415.9171])\n",
      "tensor([531.5760, 455.2574]) tensor([535.9187, 456.5209])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 230.7ms\n",
      "Speed: 2.0ms preprocess, 230.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([533.0505, 455.9703]) tensor([540.3446, 436.1112])\n",
      "tensor([534.2249, 457.2032]) tensor([541.8652, 437.8593])\n",
      "tensor([540.2120, 415.4949]) tensor([538.1971, 416.6864])\n",
      "tensor([533.0505, 455.9703]) tensor([534.2249, 457.2032])\n",
      "\n",
      "0: 384x640 2 persons, 290.3ms\n",
      "Speed: 3.5ms preprocess, 290.3ms inference, 2.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([544.4823, 450.2070]) tensor([547.4690, 433.4361])\n",
      "tensor([530.8107, 458.1808]) tensor([534.8574, 439.4036])\n",
      "tensor([539.6418, 415.7103]) tensor([533.7739, 418.0569])\n",
      "tensor([544.4823, 450.2070]) tensor([530.8107, 458.1808])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 251.0ms\n",
      "Speed: 2.0ms preprocess, 251.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([579.5645, 310.1666]) tensor([577.5911, 293.7238])\n",
      "tensor([608.7130, 308.1402]) tensor([609.6190, 291.4636])\n",
      "tensor([583.2417, 276.2708]) tensor([603.3405, 275.2085])\n",
      "tensor([579.5645, 310.1666]) tensor([608.7130, 308.1402])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 225.1ms\n",
      "Speed: 3.1ms preprocess, 225.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([580.5173, 310.9703]) tensor([578.9250, 294.3737])\n",
      "tensor([611.1763, 309.1638]) tensor([611.9201, 292.0809])\n",
      "tensor([584.5200, 277.3563]) tensor([604.9096, 276.2063])\n",
      "tensor([580.5173, 310.9703]) tensor([611.1763, 309.1638])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 211.9ms\n",
      "Speed: 3.0ms preprocess, 211.9ms inference, 0.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([583.3242, 314.0439]) tensor([580.6808, 297.4018])\n",
      "tensor([609.3050, 312.8709]) tensor([608.8346, 296.8038])\n",
      "tensor([586.8407, 279.7887]) tensor([604.8403, 279.9114])\n",
      "tensor([583.3242, 314.0439]) tensor([609.3050, 312.8709])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 232.8ms\n",
      "Speed: 1.5ms preprocess, 232.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([583.1591, 314.4131]) tensor([581.3594, 297.7282])\n",
      "tensor([610.2372, 313.4167]) tensor([609.4263, 297.7622])\n",
      "tensor([588.3858, 280.4901]) tensor([605.9637, 281.0880])\n",
      "tensor([583.1591, 314.4131]) tensor([610.2372, 313.4167])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 202.5ms\n",
      "Speed: 2.0ms preprocess, 202.5ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([587.3131, 313.9494]) tensor([584.7567, 297.9790])\n",
      "tensor([611.3658, 312.9019]) tensor([610.4965, 298.2326])\n",
      "tensor([591.7558, 280.6008]) tensor([608.1614, 281.4085])\n",
      "tensor([587.3131, 313.9494]) tensor([611.3658, 312.9019])\n",
      "2\n",
      "\n",
      "0: 384x640 (no detections), 225.0ms\n",
      "Speed: 1.8ms preprocess, 225.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "\n",
      "0: 384x640 1 person, 212.9ms\n",
      "Speed: 2.0ms preprocess, 212.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([1009.1356,  218.8002]) tensor([1006.2916,  209.1905])\n",
      "tensor([1036.6738,  192.0362]) tensor([1041.3907,  197.5453])\n",
      "tensor([1012.4711,  186.4687]) tensor([1036.4672,  183.7048])\n",
      "tensor([1009.1356,  218.8002]) tensor([1036.6738,  192.0362])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 212.2ms\n",
      "Speed: 2.1ms preprocess, 212.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([521.4095, 416.5705]) tensor([524.0424, 414.6363])\n",
      "tensor([535.0142, 418.0909]) tensor([537.2715, 414.9614])\n",
      "tensor([524.3800, 402.6690]) tensor([529.3432, 402.8088])\n",
      "tensor([521.4095, 416.5705]) tensor([535.0142, 418.0909])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 215.1ms\n",
      "Speed: 2.0ms preprocess, 215.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([533.6776, 429.2479]) tensor([540.6049, 417.4645])\n",
      "tensor([520.1593, 433.6219]) tensor([525.0054, 421.7687])\n",
      "tensor([535.5096, 401.0400]) tensor([524.5577, 403.4515])\n",
      "tensor([533.6776, 429.2479]) tensor([520.1593, 433.6219])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 213.6ms\n",
      "Speed: 2.0ms preprocess, 213.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([527.9278, 438.6617]) tensor([541.4036, 418.7035])\n",
      "tensor([516.8085, 443.0709]) tensor([522.4836, 423.7817])\n",
      "tensor([538.9595, 400.6105]) tensor([525.1054, 403.2339])\n",
      "tensor([527.9278, 438.6617]) tensor([516.8085, 443.0709])\n",
      "\n",
      "0: 384x640 2 persons, 211.3ms\n",
      "Speed: 1.5ms preprocess, 211.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([525.5037, 436.2890]) tensor([540.6531, 416.4222])\n",
      "tensor([517.8361, 440.2405]) tensor([522.3889, 420.8308])\n",
      "tensor([538.7253, 398.7922]) tensor([525.5881, 401.0927])\n",
      "tensor([525.5037, 436.2890]) tensor([517.8361, 440.2405])\n",
      "\n",
      "0: 384x640 2 persons, 214.0ms\n",
      "Speed: 3.0ms preprocess, 214.0ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([505.8964, 435.5211]) tensor([516.4129, 416.2101])\n",
      "tensor([551.0433, 436.9281]) tensor([549.5881, 416.1212])\n",
      "tensor([522.4034, 398.8925]) tensor([537.9312, 398.2169])\n",
      "tensor([505.8964, 435.5211]) tensor([551.0433, 436.9281])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 216.9ms\n",
      "Speed: 3.5ms preprocess, 216.9ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([521.7950, 430.0302]) tensor([536.6127, 412.5459])\n",
      "tensor([532.7874, 432.3357]) tensor([530.9465, 414.3333])\n",
      "tensor([535.3177, 397.8363]) tensor([529.7976, 398.6591])\n",
      "tensor([521.7950, 430.0302]) tensor([532.7874, 432.3357])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 210.6ms\n",
      "Speed: 3.6ms preprocess, 210.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([519.8854, 427.4179]) tensor([532.8018, 411.7448])\n",
      "tensor([536.2780, 428.4673]) tensor([534.7963, 412.4947])\n",
      "tensor([534.0225, 397.2773]) tensor([534.1442, 397.6606])\n",
      "tensor([519.8854, 427.4179]) tensor([536.2780, 428.4673])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 220.2ms\n",
      "Speed: 2.0ms preprocess, 220.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([553.4380, 427.3768]) tensor([559.7545, 413.0302])\n",
      "tensor([516.0645, 429.8740]) tensor([515.3141, 414.5823])\n",
      "tensor([547.3170, 396.4349]) tensor([523.3939, 398.0756])\n",
      "tensor([553.4380, 427.3768]) tensor([516.0645, 429.8740])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 235.7ms\n",
      "Speed: 3.0ms preprocess, 235.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([537.6042, 427.0928]) tensor([549.4799, 411.9501])\n",
      "tensor([520.4349, 428.2949]) tensor([522.2630, 413.1597])\n",
      "tensor([545.6798, 395.9653]) tensor([529.4366, 397.0556])\n",
      "tensor([537.6042, 427.0928]) tensor([520.4349, 428.2949])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 216.0ms\n",
      "Speed: 3.0ms preprocess, 216.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([522.7990, 426.0089]) tensor([524.6581, 412.1667])\n",
      "tensor([561.4318, 425.9534]) tensor([561.3195, 410.7981])\n",
      "tensor([529.2717, 394.5086]) tensor([550.7581, 393.2531])\n",
      "tensor([522.7990, 426.0089]) tensor([561.4318, 425.9534])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 220.0ms\n",
      "Speed: 1.0ms preprocess, 220.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([524.1442, 429.9730]) tensor([525.5822, 412.8929])\n",
      "tensor([570.9617, 428.4502]) tensor([566.2357, 409.6995])\n",
      "tensor([530.1098, 394.2215]) tensor([552.6829, 392.3538])\n",
      "tensor([524.1442, 429.9730]) tensor([570.9617, 428.4502])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 220.8ms\n",
      "Speed: 3.0ms preprocess, 220.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([546.9719, 431.0684]) tensor([555.1194, 412.6699])\n",
      "tensor([540.3641, 433.1049]) tensor([538.7388, 414.7165])\n",
      "tensor([550.4335, 394.3997]) tensor([539.7275, 395.5126])\n",
      "tensor([546.9719, 431.0684]) tensor([540.3641, 433.1049])\n",
      "\n",
      "0: 384x640 2 persons, 213.4ms\n",
      "Speed: 3.1ms preprocess, 213.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([570.2929, 432.9144]) tensor([567.8489, 417.2226])\n",
      "tensor([529.8549, 436.2137]) tensor([534.3889, 418.9011])\n",
      "tensor([557.9852, 396.7959]) tensor([537.5854, 397.9745])\n",
      "tensor([570.2929, 432.9144]) tensor([529.8549, 436.2137])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 234.7ms\n",
      "Speed: 1.0ms preprocess, 234.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([574.5612, 435.1561]) tensor([570.5602, 420.4043])\n",
      "tensor([529.3407, 438.7546]) tensor([535.0275, 421.6204])\n",
      "tensor([559.4689, 399.7258]) tensor([539.9572, 400.4400])\n",
      "tensor([574.5612, 435.1561]) tensor([529.3407, 438.7546])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 228.0ms\n",
      "Speed: 2.0ms preprocess, 228.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([579.5874, 438.1995]) tensor([572.3719, 422.7734])\n",
      "tensor([532.3798, 443.0562]) tensor([535.8353, 426.0411])\n",
      "tensor([561.1819, 402.9161]) tensor([539.7802, 404.9160])\n",
      "tensor([579.5874, 438.1995]) tensor([532.3798, 443.0562])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 225.8ms\n",
      "Speed: 3.0ms preprocess, 225.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([581.9641, 442.8677]) tensor([575.1437, 426.6313])\n",
      "tensor([534.2007, 447.5212]) tensor([536.0828, 430.1906])\n",
      "tensor([563.7719, 406.5532]) tensor([540.6605, 408.7593])\n",
      "tensor([581.9641, 442.8677]) tensor([534.2007, 447.5212])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 233.8ms\n",
      "Speed: 3.0ms preprocess, 233.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([579.6406, 451.0246]) tensor([579.8771, 431.3934])\n",
      "tensor([536.6877, 452.8928]) tensor([538.2020, 432.6071])\n",
      "tensor([567.4486, 408.6933]) tensor([543.7322, 410.2188])\n",
      "tensor([579.6406, 451.0246]) tensor([536.6877, 452.8928])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 222.4ms\n",
      "Speed: 3.0ms preprocess, 222.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([586.6050, 450.1940]) tensor([580.9646, 432.1397])\n",
      "tensor([534.5476, 453.7284]) tensor([538.5719, 434.3767])\n",
      "tensor([567.8135, 410.7481]) tensor([547.3041, 411.6917])\n",
      "tensor([586.6050, 450.1940]) tensor([534.5476, 453.7284])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 226.2ms\n",
      "Speed: 2.5ms preprocess, 226.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([586.9894, 449.4971]) tensor([581.2737, 433.0408])\n",
      "tensor([537.1046, 451.1852]) tensor([538.9139, 434.6932])\n",
      "tensor([569.4498, 411.9788]) tensor([546.9451, 412.9628])\n",
      "tensor([586.9894, 449.4971]) tensor([537.1046, 451.1852])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 224.9ms\n",
      "Speed: 3.0ms preprocess, 224.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([590.5809, 452.5123]) tensor([583.6245, 435.5881])\n",
      "tensor([537.4800, 451.0627]) tensor([540.3060, 435.8188])\n",
      "tensor([569.6787, 413.5197]) tensor([549.3669, 414.3546])\n",
      "tensor([590.5809, 452.5123]) tensor([537.4800, 451.0627])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 225.7ms\n",
      "Speed: 1.5ms preprocess, 225.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([590.9448, 453.9193]) tensor([585.8328, 437.2481])\n",
      "tensor([538.1318, 455.2068]) tensor([542.4866, 438.3413])\n",
      "tensor([569.3691, 415.9633]) tensor([552.0255, 416.8465])\n",
      "tensor([590.9448, 453.9193]) tensor([538.1318, 455.2068])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 247.2ms\n",
      "Speed: 2.0ms preprocess, 247.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([565.0013, 456.0463]) tensor([575.9631, 436.4528])\n",
      "tensor([553.5699, 457.2306]) tensor([547.4042, 437.3434])\n",
      "tensor([569.9071, 419.3407]) tensor([553.4806, 420.0764])\n",
      "tensor([565.0013, 456.0463]) tensor([553.5699, 457.2306])\n",
      "\n",
      "0: 384x640 2 persons, 218.2ms\n",
      "Speed: 2.0ms preprocess, 218.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([561.8356, 456.2597]) tensor([573.6036, 436.5065])\n",
      "tensor([560.7155, 457.3388]) tensor([552.1121, 437.5368])\n",
      "tensor([569.1890, 420.5310]) tensor([556.2986, 421.1102])\n",
      "tensor([561.8356, 456.2597]) tensor([560.7155, 457.3388])\n",
      "\n",
      "0: 384x640 2 persons, 223.6ms\n",
      "Speed: 2.1ms preprocess, 223.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([606.8323, 445.0408]) tensor([595.6657, 435.6473])\n",
      "tensor([539.3619, 452.7338]) tensor([544.3396, 440.2914])\n",
      "tensor([577.9885, 418.1989]) tensor([554.4142, 419.6276])\n",
      "tensor([606.8323, 445.0408]) tensor([539.3619, 452.7338])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 210.8ms\n",
      "Speed: 2.0ms preprocess, 210.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([607.5230, 445.6295]) tensor([597.3064, 434.1755])\n",
      "tensor([542.5604, 455.8596]) tensor([547.2435, 440.3473])\n",
      "tensor([579.9185, 416.5549]) tensor([556.5520, 418.4246])\n",
      "tensor([607.5230, 445.6295]) tensor([542.5604, 455.8596])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 225.8ms\n",
      "Speed: 3.1ms preprocess, 225.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([608.9709, 445.4336]) tensor([600.7056, 433.8143])\n",
      "tensor([545.5750, 457.4317]) tensor([550.3336, 440.5492])\n",
      "tensor([581.7935, 415.8828]) tensor([558.6276, 417.6269])\n",
      "tensor([608.9709, 445.4336]) tensor([545.5750, 457.4317])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 226.9ms\n",
      "Speed: 2.0ms preprocess, 226.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([593.6681, 452.5418]) tensor([592.2626, 435.5957])\n",
      "tensor([562.6974, 455.2508]) tensor([558.8068, 437.3546])\n",
      "tensor([579.6614, 415.6264]) tensor([564.1743, 417.1318])\n",
      "tensor([593.6681, 452.5418]) tensor([562.6974, 455.2508])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 224.8ms\n",
      "Speed: 1.5ms preprocess, 224.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([608.8930, 450.6229]) tensor([604.1803, 437.3109])\n",
      "tensor([555.5554, 457.5068]) tensor([555.8890, 442.4026])\n",
      "tensor([588.4584, 418.4839]) tensor([561.6596, 421.1957])\n",
      "tensor([608.8930, 450.6229]) tensor([555.5554, 457.5068])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 252.2ms\n",
      "Speed: 2.0ms preprocess, 252.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([610.6518, 456.5274]) tensor([604.8654, 441.5051])\n",
      "tensor([558.5375, 461.9857]) tensor([557.1818, 445.5733])\n",
      "tensor([590.3189, 422.3582]) tensor([562.6801, 424.5006])\n",
      "tensor([610.6518, 456.5274]) tensor([558.5375, 461.9857])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 217.9ms\n",
      "Speed: 2.0ms preprocess, 217.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([611.9421, 451.8759]) tensor([608.7186, 444.4923])\n",
      "tensor([562.2750, 458.3777]) tensor([560.9708, 449.0163])\n",
      "tensor([592.2312, 426.6183]) tensor([564.9160, 428.7551])\n",
      "tensor([611.9421, 451.8759]) tensor([562.2750, 458.3777])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 214.5ms\n",
      "Speed: 3.0ms preprocess, 214.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([613.0222, 453.3312]) tensor([609.2184, 447.6714])\n",
      "tensor([565.4282, 457.9329]) tensor([563.2920, 451.1911])\n",
      "tensor([593.0273, 430.6868]) tensor([565.4811, 432.4926])\n",
      "tensor([613.0222, 453.3312]) tensor([565.4282, 457.9329])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 215.0ms\n",
      "Speed: 2.2ms preprocess, 215.0ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([611.8809, 443.6710]) tensor([609.2587, 449.0748])\n",
      "tensor([573.2314, 438.8992]) tensor([564.7468, 448.1567])\n",
      "1\n",
      "tensor([594.2211, 435.8347]) tensor([567.6919, 436.4547])\n",
      "tensor([611.8809, 443.6710]) tensor([573.2314, 438.8992])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 223.4ms\n",
      "Speed: 1.4ms preprocess, 223.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([612.2491, 434.1311]) tensor([614.6566, 448.2065])\n",
      "tensor([579.7512, 426.3956]) tensor([568.0301, 446.1113])\n",
      "1\n",
      "tensor([600.2164, 443.4376]) tensor([573.6794, 444.0193])\n",
      "tensor([612.2491, 434.1311]) tensor([579.7512, 426.3956])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 223.8ms\n",
      "Speed: 2.0ms preprocess, 223.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([633.6660, 427.4279]) tensor([628.5882, 441.9951])\n",
      "tensor([566.7308, 426.9539]) tensor([564.4915, 441.7882])\n",
      "1\n",
      "tensor([608.2875, 439.4742]) tensor([580.4523, 439.3294])\n",
      "tensor([633.6660, 427.4279]) tensor([566.7308, 426.9539])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 228.3ms\n",
      "Speed: 2.0ms preprocess, 228.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([640.3315, 443.2456]) tensor([633.1292, 453.6534])\n",
      "tensor([574.5034, 424.4027]) tensor([570.7988, 443.9281])\n",
      "1\n",
      "tensor([616.5955, 446.5837]) tensor([588.0054, 443.8564])\n",
      "tensor([640.3315, 443.2456]) tensor([574.5034, 424.4027])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 220.0ms\n",
      "Speed: 2.0ms preprocess, 220.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([646.2274, 442.4460]) tensor([643.9618, 446.4761])\n",
      "tensor([570.6308, 437.9637]) tensor([574.2297, 443.3636])\n",
      "1\n",
      "tensor([626.3025, 443.3420]) tensor([597.7186, 441.3647])\n",
      "tensor([646.2274, 442.4460]) tensor([570.6308, 437.9637])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 228.0ms\n",
      "Speed: 2.1ms preprocess, 228.0ms inference, 1.8ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([658.9661, 455.4897]) tensor([652.9037, 452.3714])\n",
      "tensor([573.1238, 435.1762]) tensor([578.9609, 441.9507])\n",
      "tensor([634.9315, 444.8559]) tensor([604.3741, 441.8941])\n",
      "tensor([658.9661, 455.4897]) tensor([573.1238, 435.1762])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 220.0ms\n",
      "Speed: 2.0ms preprocess, 220.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([661.4465, 453.5695]) tensor([652.7035, 454.7536])\n",
      "tensor([585.1225, 438.3451]) tensor([591.7039, 445.0674])\n",
      "1\n",
      "tensor([636.5145, 445.6973]) tensor([613.8906, 442.7358])\n",
      "tensor([661.4465, 453.5695]) tensor([585.1225, 438.3451])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 228.9ms\n",
      "Speed: 2.0ms preprocess, 228.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([654.8521, 469.7529]) tensor([651.7745, 462.7823])\n",
      "tensor([619.5622, 470.4071]) tensor([611.4234, 462.6066])\n",
      "tensor([642.8200, 445.7688]) tensor([615.4557, 444.9230])\n",
      "tensor([654.8521, 469.7529]) tensor([619.5622, 470.4071])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 229.5ms\n",
      "Speed: 2.0ms preprocess, 229.5ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([659.7207, 461.1380]) tensor([659.4036, 462.1951])\n",
      "tensor([618.6806, 461.1198]) tensor([619.1092, 461.7917])\n",
      "1\n",
      "tensor([651.2264, 447.8660]) tensor([627.0102, 448.0197])\n",
      "tensor([659.7207, 461.1380]) tensor([618.6806, 461.1198])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 225.2ms\n",
      "Speed: 2.0ms preprocess, 225.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([681.7700, 456.7823]) tensor([668.5532, 463.9509])\n",
      "tensor([651.1720, 452.4385]) tensor([636.8546, 462.1784])\n",
      "1\n",
      "tensor([653.2160, 451.2894]) tensor([632.7252, 450.3996])\n",
      "tensor([681.7700, 456.7823]) tensor([651.1720, 452.4385])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 228.9ms\n",
      "Speed: 2.0ms preprocess, 228.9ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([697.6130, 454.1569]) tensor([676.1669, 463.6458])\n",
      "tensor([690.8646, 450.7733]) tensor([667.8719, 462.9654])\n",
      "1\n",
      "tensor([657.0232, 454.9196]) tensor([648.1111, 454.4080])\n",
      "tensor([697.6130, 454.1569]) tensor([690.8646, 450.7733])\n",
      "\n",
      "0: 384x640 2 persons, 219.3ms\n",
      "Speed: 3.0ms preprocess, 219.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([701.9455, 453.8847]) tensor([684.6711, 462.8906])\n",
      "tensor([700.0480, 453.5489]) tensor([677.8434, 464.6085])\n",
      "1\n",
      "tensor([665.2897, 453.8905]) tensor([658.6660, 454.5050])\n",
      "tensor([701.9455, 453.8847]) tensor([700.0480, 453.5489])\n",
      "\n",
      "0: 384x640 2 persons, 216.2ms\n",
      "Speed: 3.0ms preprocess, 216.2ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([701.0874, 456.9785]) tensor([684.9194, 468.1125])\n",
      "tensor([704.5945, 456.8996]) tensor([693.6332, 469.8423])\n",
      "1\n",
      "tensor([669.9205, 461.4526]) tensor([679.1693, 463.1595])\n",
      "tensor([701.0874, 456.9785]) tensor([704.5945, 456.8996])\n",
      "\n",
      "0: 384x640 2 persons, 239.8ms\n",
      "Speed: 2.6ms preprocess, 239.8ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([706.2430, 443.9289]) tensor([699.3490, 461.0960])\n",
      "tensor([691.4005, 448.1871]) tensor([676.4706, 461.8745])\n",
      "1\n",
      "tensor([688.5566, 464.3734]) tensor([672.3987, 462.8819])\n",
      "tensor([706.2430, 443.9289]) tensor([691.4005, 448.1871])\n",
      "\n",
      "0: 384x640 2 persons, 220.7ms\n",
      "Speed: 2.0ms preprocess, 220.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([704.1786, 452.5762]) tensor([696.0712, 464.5131])\n",
      "tensor([712.9595, 447.0115]) tensor([702.9979, 462.5561])\n",
      "1\n",
      "tensor([694.0695, 464.0458]) tensor([692.8116, 462.9391])\n",
      "tensor([704.1786, 452.5762]) tensor([712.9595, 447.0115])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 229.5ms\n",
      "Speed: 1.6ms preprocess, 229.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([705.3640, 443.2511]) tensor([700.8203, 459.5747])\n",
      "tensor([707.8737, 441.7207]) tensor([698.1265, 458.5651])\n",
      "1\n",
      "tensor([701.1587, 464.1153]) tensor([695.2006, 462.7670])\n",
      "tensor([705.3640, 443.2511]) tensor([707.8737, 441.7207])\n",
      "\n",
      "0: 384x640 2 persons, 218.8ms\n",
      "Speed: 3.0ms preprocess, 218.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([712.4571, 462.7111]) tensor([706.2208, 469.4730])\n",
      "tensor([710.7248, 459.9563]) tensor([702.0601, 467.3313])\n",
      "1\n",
      "tensor([706.0058, 459.5540]) tensor([703.8277, 457.8683])\n",
      "tensor([712.4571, 462.7111]) tensor([710.7248, 459.9563])\n",
      "\n",
      "0: 384x640 2 persons, 214.0ms\n",
      "Speed: 2.5ms preprocess, 214.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([702.1980, 442.9157]) tensor([710.1663, 455.6509])\n",
      "tensor([693.1556, 441.7557]) tensor([693.4879, 455.8111])\n",
      "1\n",
      "tensor([715.8358, 456.2975]) tensor([707.8845, 456.2604])\n",
      "tensor([702.1980, 442.9157]) tensor([693.1556, 441.7557])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 255.7ms\n",
      "Speed: 2.3ms preprocess, 255.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([704.5829, 452.5822]) tensor([703.6740, 463.7308])\n",
      "tensor([709.1214, 451.9021]) tensor([718.5718, 464.8802])\n",
      "1\n",
      "tensor([714.3801, 456.5693]) tensor([727.8142, 456.9734])\n",
      "tensor([704.5829, 452.5822]) tensor([709.1214, 451.9021])\n",
      "\n",
      "0: 384x640 1 person, 225.0ms\n",
      "Speed: 2.0ms preprocess, 225.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([700.8221, 456.3572]) tensor([705.9963, 466.9712])\n",
      "tensor([715.6085, 456.7872]) tensor([729.5098, 469.4327])\n",
      "1\n",
      "tensor([720.1901, 461.0946]) tensor([735.7212, 461.7354])\n",
      "tensor([700.8221, 456.3572]) tensor([715.6085, 456.7872])\n",
      "\n",
      "0: 384x640 2 persons, 225.9ms\n",
      "Speed: 2.0ms preprocess, 225.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([712.1303, 461.7522]) tensor([711.4299, 472.2771])\n",
      "tensor([752.9871, 467.6342]) tensor([753.5815, 476.1191])\n",
      "1\n",
      "tensor([725.7360, 467.8442]) tensor([745.8788, 468.8719])\n",
      "tensor([712.1303, 461.7522]) tensor([752.9871, 467.6342])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 212.8ms\n",
      "Speed: 3.0ms preprocess, 212.8ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([770.8030, 461.8975]) tensor([770.4282, 470.3484])\n",
      "tensor([724.1691, 460.9777]) tensor([721.2596, 470.2624])\n",
      "1\n",
      "tensor([751.6654, 474.1938]) tensor([732.0142, 472.9600])\n",
      "tensor([770.8030, 461.8975]) tensor([724.1691, 460.9777])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 217.2ms\n",
      "Speed: 2.5ms preprocess, 217.2ms inference, 1.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([785.6239, 470.5066]) tensor([775.9917, 480.4762])\n",
      "tensor([751.7756, 475.7782]) tensor([742.9387, 485.8333])\n",
      "1\n",
      "tensor([757.1354, 477.0424]) tensor([738.5504, 478.0542])\n",
      "tensor([785.6239, 470.5066]) tensor([751.7756, 475.7782])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 222.2ms\n",
      "Speed: 2.0ms preprocess, 222.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([811.4116, 456.7590]) tensor([796.0363, 476.1092])\n",
      "tensor([754.9606, 482.6700]) tensor([748.3438, 491.9122])\n",
      "1\n",
      "tensor([763.8644, 483.6081]) tensor([747.3812, 487.7593])\n",
      "tensor([811.4116, 456.7590]) tensor([754.9606, 482.6700])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 238.8ms\n",
      "Speed: 2.0ms preprocess, 238.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([816.4744, 467.2750]) tensor([800.3326, 486.9992])\n",
      "tensor([763.2440, 490.4623]) tensor([753.7172, 500.1658])\n",
      "1\n",
      "tensor([773.9243, 490.9890]) tensor([753.1243, 494.0612])\n",
      "tensor([816.4744, 467.2750]) tensor([763.2440, 490.4623])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 235.0ms\n",
      "Speed: 2.0ms preprocess, 235.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([816.1871, 487.3322]) tensor([802.0397, 497.8605])\n",
      "tensor([776.1711, 495.6308]) tensor([752.1638, 503.4316])\n",
      "1\n",
      "tensor([778.0074, 497.0692]) tensor([756.8586, 498.8416])\n",
      "tensor([816.1871, 487.3322]) tensor([776.1711, 495.6308])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 226.5ms\n",
      "Speed: 2.0ms preprocess, 226.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([814.6148, 492.2004]) tensor([803.0010, 501.4014])\n",
      "tensor([765.7280, 502.6570]) tensor([749.0759, 506.1394])\n",
      "1\n",
      "tensor([781.7181, 497.0056]) tensor([760.0933, 497.4913])\n",
      "tensor([814.6148, 492.2004]) tensor([765.7280, 502.6570])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 216.8ms\n",
      "Speed: 3.0ms preprocess, 216.8ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([812.1978, 497.4100]) tensor([800.0002, 506.2397])\n",
      "tensor([762.9683, 499.9682]) tensor([753.5093, 503.8363])\n",
      "1\n",
      "tensor([783.0167, 494.4988]) tensor([761.7535, 491.0159])\n",
      "tensor([812.1978, 497.4100]) tensor([762.9683, 499.9682])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 215.3ms\n",
      "Speed: 2.0ms preprocess, 215.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([781.3088, 501.7393]) tensor([774.3843, 504.7043])\n",
      "tensor([789.2352, 500.6130]) tensor([777.0619, 504.1830])\n",
      "1\n",
      "tensor([775.3356, 490.1687]) tensor([772.5563, 488.9070])\n",
      "tensor([781.3088, 501.7393]) tensor([789.2352, 500.6130])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 229.9ms\n",
      "Speed: 2.0ms preprocess, 229.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([784.3882, 515.4404]) tensor([788.5483, 509.5486])\n",
      "tensor([751.6079, 502.4111]) tensor([750.0576, 501.0770])\n",
      "tensor([784.6516, 488.4890]) tensor([763.0616, 484.2178])\n",
      "tensor([784.3882, 515.4404]) tensor([751.6079, 502.4111])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 220.8ms\n",
      "Speed: 2.3ms preprocess, 220.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([785.9805, 535.5771]) tensor([789.5715, 514.4382])\n",
      "tensor([746.6199, 517.1646]) tensor([745.6333, 502.9288])\n",
      "tensor([786.7172, 487.3222]) tensor([758.2304, 482.6005])\n",
      "tensor([785.9805, 535.5771]) tensor([746.6199, 517.1646])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 223.2ms\n",
      "Speed: 2.0ms preprocess, 223.2ms inference, 1.4ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([780.5535, 534.2337]) tensor([785.2986, 515.0296])\n",
      "tensor([740.2043, 517.0001]) tensor([740.1006, 500.4796])\n",
      "tensor([782.3961, 486.8427]) tensor([753.8245, 479.4796])\n",
      "tensor([780.5535, 534.2337]) tensor([740.2043, 517.0001])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 221.5ms\n",
      "Speed: 3.0ms preprocess, 221.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([778.4917, 532.8721]) tensor([784.0104, 515.6084])\n",
      "tensor([734.0833, 516.9593]) tensor([737.3657, 501.8985])\n",
      "tensor([780.9376, 487.9376]) tensor([751.6823, 481.2461])\n",
      "tensor([778.4917, 532.8721]) tensor([734.0833, 516.9593])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 252.0ms\n",
      "Speed: 2.0ms preprocess, 252.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([776.5501, 529.1009]) tensor([782.1398, 513.8301])\n",
      "tensor([731.9061, 524.0860]) tensor([734.4933, 506.0574])\n",
      "tensor([781.4545, 488.0544]) tensor([748.9949, 484.1507])\n",
      "tensor([776.5501, 529.1009]) tensor([731.9061, 524.0860])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 214.1ms\n",
      "Speed: 2.0ms preprocess, 214.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([773.2973, 528.9406]) tensor([777.7236, 514.4905])\n",
      "tensor([726.3182, 531.5504]) tensor([730.0039, 511.0648])\n",
      "tensor([775.3129, 489.3974]) tensor([744.3593, 486.9484])\n",
      "tensor([773.2973, 528.9406]) tensor([726.3182, 531.5504])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 218.6ms\n",
      "Speed: 3.0ms preprocess, 218.6ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([767.7761, 522.5700]) tensor([776.0633, 509.5784])\n",
      "tensor([721.2766, 536.5837]) tensor([728.0819, 515.4301])\n",
      "tensor([770.2929, 488.9913]) tensor([739.1713, 488.4958])\n",
      "tensor([767.7761, 522.5700]) tensor([721.2766, 536.5837])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 215.7ms\n",
      "Speed: 2.0ms preprocess, 215.7ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([760.9874, 516.7386]) tensor([770.9262, 506.0580])\n",
      "tensor([712.9382, 531.9575]) tensor([724.0487, 512.1567])\n",
      "tensor([765.3318, 486.2981]) tensor([735.5758, 486.1707])\n",
      "tensor([760.9874, 516.7386]) tensor([712.9382, 531.9575])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 235.1ms\n",
      "Speed: 3.0ms preprocess, 235.1ms inference, 3.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([750.9233, 508.2223]) tensor([762.0452, 499.6312])\n",
      "tensor([707.3902, 528.3597]) tensor([718.8517, 508.7017])\n",
      "tensor([755.5188, 480.7034]) tensor([727.9375, 481.9506])\n",
      "tensor([750.9233, 508.2223]) tensor([707.3902, 528.3597])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 273.6ms\n",
      "Speed: 3.1ms preprocess, 273.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([745.1459, 517.1237]) tensor([752.7365, 501.1339])\n",
      "tensor([706.3434, 524.5154]) tensor([715.6315, 503.1470])\n",
      "tensor([747.4595, 478.6668]) tensor([722.9245, 478.1492])\n",
      "tensor([745.1459, 517.1237]) tensor([706.3434, 524.5154])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 217.8ms\n",
      "Speed: 3.1ms preprocess, 217.8ms inference, 1.6ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([747.8268, 516.3877]) tensor([750.2960, 497.1278])\n",
      "tensor([700.5770, 516.8776]) tensor([708.4583, 496.6047])\n",
      "tensor([742.2543, 473.1694]) tensor([715.8604, 472.9138])\n",
      "tensor([747.8268, 516.3877]) tensor([700.5770, 516.8776])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 216.4ms\n",
      "Speed: 2.0ms preprocess, 216.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([744.6315, 508.3004]) tensor([747.0090, 491.1263])\n",
      "tensor([694.7382, 509.4009]) tensor([702.0827, 490.4482])\n",
      "tensor([739.2990, 468.3903]) tensor([710.9917, 468.0965])\n",
      "tensor([744.6315, 508.3004]) tensor([694.7382, 509.4009])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 210.7ms\n",
      "Speed: 2.0ms preprocess, 210.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([747.1270, 514.9252]) tensor([745.7961, 490.8156])\n",
      "tensor([691.4941, 507.6290]) tensor([699.8464, 486.9373])\n",
      "tensor([736.8959, 463.3145]) tensor([709.1514, 462.9409])\n",
      "tensor([747.1270, 514.9252]) tensor([691.4941, 507.6290])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 212.4ms\n",
      "Speed: 3.0ms preprocess, 212.4ms inference, 1.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([744.5563, 508.3179]) tensor([740.9912, 486.6097])\n",
      "tensor([686.6413, 499.4643]) tensor([693.5056, 481.4594])\n",
      "tensor([734.0814, 460.3380]) tensor([705.0175, 459.6130])\n",
      "tensor([744.5563, 508.3179]) tensor([686.6413, 499.4643])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 213.2ms\n",
      "Speed: 2.5ms preprocess, 213.2ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([741.6668, 500.6010]) tensor([737.6039, 480.2650])\n",
      "tensor([688.7394, 489.3274]) tensor([689.8970, 475.0183])\n",
      "tensor([729.1481, 454.7265]) tensor([699.3699, 454.3831])\n",
      "tensor([741.6668, 500.6010]) tensor([688.7394, 489.3274])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 222.8ms\n",
      "Speed: 2.0ms preprocess, 222.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([740.4080, 495.0194]) tensor([735.4094, 477.0617])\n",
      "tensor([685.1569, 478.5569]) tensor([686.8682, 468.9219])\n",
      "tensor([726.5654, 452.4271]) tensor([697.0961, 451.2137])\n",
      "tensor([740.4080, 495.0194]) tensor([685.1569, 478.5569])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 215.9ms\n",
      "Speed: 2.4ms preprocess, 215.9ms inference, 0.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([739.6297, 489.9182]) tensor([734.9421, 472.3650])\n",
      "tensor([681.0568, 473.5484]) tensor([685.3954, 465.8973])\n",
      "tensor([723.4968, 447.8041]) tensor([696.3416, 447.0359])\n",
      "tensor([739.6297, 489.9182]) tensor([681.0568, 473.5484])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 233.7ms\n",
      "Speed: 1.0ms preprocess, 233.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([738.8963, 489.3903]) tensor([731.6592, 471.6419])\n",
      "tensor([679.0830, 473.5540]) tensor([681.3389, 464.8161])\n",
      "tensor([720.4788, 447.5542]) tensor([691.9597, 446.3973])\n",
      "tensor([738.8963, 489.3903]) tensor([679.0830, 473.5540])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 239.4ms\n",
      "Speed: 2.0ms preprocess, 239.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([739.8915, 490.5775]) tensor([730.2072, 471.4619])\n",
      "tensor([677.2590, 474.0423]) tensor([678.2150, 463.1622])\n",
      "tensor([716.3770, 448.3021]) tensor([689.0532, 446.0425])\n",
      "tensor([739.8915, 490.5775]) tensor([677.2590, 474.0423])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 220.8ms\n",
      "Speed: 2.0ms preprocess, 220.8ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([737.2081, 492.6566]) tensor([728.2244, 472.9916])\n",
      "tensor([675.8251, 480.2207]) tensor([679.6856, 466.1631])\n",
      "tensor([712.0776, 449.7990]) tensor([688.4660, 447.7074])\n",
      "tensor([737.2081, 492.6566]) tensor([675.8251, 480.2207])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 224.4ms\n",
      "Speed: 1.5ms preprocess, 224.4ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([729.7445, 491.1134]) tensor([722.9274, 473.9789])\n",
      "tensor([675.3919, 492.7919]) tensor([676.7767, 474.9892])\n",
      "tensor([709.7971, 452.2097]) tensor([681.9448, 452.5400])\n",
      "tensor([729.7445, 491.1134]) tensor([675.3919, 492.7919])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 223.3ms\n",
      "Speed: 2.0ms preprocess, 223.3ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([702.2914, 491.0204]) tensor([700.2748, 474.9591])\n",
      "tensor([715.7355, 492.2853]) tensor([703.7771, 475.6766])\n",
      "tensor([694.1018, 455.7689]) tensor([694.0513, 456.5464])\n",
      "tensor([702.2914, 491.0204]) tensor([715.7355, 492.2853])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 219.6ms\n",
      "Speed: 2.0ms preprocess, 219.6ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([719.1696, 495.9904]) tensor([714.6786, 478.2156])\n",
      "tensor([669.7869, 499.1245]) tensor([669.7701, 481.9799])\n",
      "tensor([701.2484, 458.1798]) tensor([672.0266, 459.5324])\n",
      "tensor([719.1696, 495.9904]) tensor([669.7869, 499.1245])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 222.4ms\n",
      "Speed: 2.0ms preprocess, 222.4ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([712.1793, 487.4903]) tensor([708.9589, 476.4218])\n",
      "tensor([664.7289, 493.0621]) tensor([661.9651, 481.2518])\n",
      "tensor([693.2916, 458.7952]) tensor([666.8264, 462.0115])\n",
      "tensor([712.1793, 487.4903]) tensor([664.7289, 493.0621])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 223.0ms\n",
      "Speed: 1.0ms preprocess, 223.0ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([707.5075, 491.0495]) tensor([698.0932, 475.9846])\n",
      "tensor([672.7235, 487.4127]) tensor([668.4516, 477.4540])\n",
      "tensor([681.1327, 456.1039]) tensor([661.0488, 457.7626])\n",
      "tensor([707.5075, 491.0495]) tensor([672.7235, 487.4127])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 253.9ms\n",
      "Speed: 2.0ms preprocess, 253.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([693.4929, 489.9176]) tensor([688.2098, 475.7451])\n",
      "tensor([670.3580, 493.5745]) tensor([664.1422, 478.7283])\n",
      "tensor([670.3031, 457.5988]) tensor([658.7282, 459.0428])\n",
      "tensor([693.4929, 489.9176]) tensor([670.3580, 493.5745])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 214.0ms\n",
      "Speed: 2.4ms preprocess, 214.0ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([684.3810, 479.2972]) tensor([680.0029, 472.5551])\n",
      "tensor([641.7548, 479.4858]) tensor([640.1084, 474.1533])\n",
      "tensor([663.2040, 457.1232]) tensor([643.8911, 458.1890])\n",
      "tensor([684.3810, 479.2972]) tensor([641.7548, 479.4858])\n",
      "2\n",
      "\n",
      "0: 384x640 1 person, 228.4ms\n",
      "Speed: 3.0ms preprocess, 228.4ms inference, 2.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([675.8981, 473.3554]) tensor([673.6138, 470.2815])\n",
      "tensor([634.4998, 478.8605]) tensor([634.3175, 474.4546])\n",
      "tensor([656.6750, 456.9898]) tensor([637.5934, 458.9271])\n",
      "tensor([675.8981, 473.3554]) tensor([634.4998, 478.8605])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 219.4ms\n",
      "Speed: 3.0ms preprocess, 219.4ms inference, 1.1ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([673.8525, 468.1590]) tensor([665.8027, 469.2422])\n",
      "tensor([627.7279, 469.9278]) tensor([622.3737, 473.7277])\n",
      "1\n",
      "tensor([650.4518, 455.7818]) tensor([625.8973, 459.4161])\n",
      "tensor([673.8525, 468.1590]) tensor([627.7279, 469.9278])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 236.6ms\n",
      "Speed: 3.2ms preprocess, 236.6ms inference, 1.5ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([664.9118, 460.0532]) tensor([657.1825, 467.2217])\n",
      "tensor([612.1111, 447.9145]) tensor([612.3646, 464.5672])\n",
      "1\n",
      "tensor([640.6194, 456.0005]) tensor([619.3258, 457.2049])\n",
      "tensor([664.9118, 460.0532]) tensor([612.1111, 447.9145])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 215.3ms\n",
      "Speed: 2.2ms preprocess, 215.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([660.6813, 454.9790]) tensor([653.2883, 462.8596])\n",
      "tensor([601.2875, 446.4252]) tensor([602.8777, 461.6841])\n",
      "1\n",
      "tensor([635.8697, 452.8409]) tensor([611.8849, 454.6139])\n",
      "tensor([660.6813, 454.9790]) tensor([601.2875, 446.4252])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 214.8ms\n",
      "Speed: 2.0ms preprocess, 214.8ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([644.2626, 455.7567]) tensor([639.2532, 465.4307])\n",
      "tensor([617.0164, 458.9217]) tensor([612.7236, 468.1248])\n",
      "1\n",
      "tensor([627.1683, 455.6903]) tensor([607.5408, 457.1312])\n",
      "tensor([644.2626, 455.7567]) tensor([617.0164, 458.9217])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 218.1ms\n",
      "Speed: 2.0ms preprocess, 218.1ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([611.8883, 462.3708]) tensor([607.3495, 473.3940])\n",
      "tensor([628.3228, 463.0319]) tensor([629.8373, 471.5239])\n",
      "1\n",
      "tensor([603.5240, 463.4854]) tensor([615.1942, 462.4830])\n",
      "tensor([611.8883, 462.3708]) tensor([628.3228, 463.0319])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 230.3ms\n",
      "Speed: 2.0ms preprocess, 230.3ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([627.1484, 469.1317]) tensor([627.8690, 471.9287])\n",
      "tensor([614.1063, 467.7127]) tensor([609.5812, 476.9653])\n",
      "1\n",
      "tensor([609.2358, 464.4329]) tensor([598.0169, 468.4714])\n",
      "tensor([627.1484, 469.1317]) tensor([614.1063, 467.7127])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 229.9ms\n",
      "Speed: 2.0ms preprocess, 229.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([666.8678, 303.3241]) tensor([663.1558, 288.7763])\n",
      "tensor([692.9536, 302.4560]) tensor([697.4130, 287.9319])\n",
      "tensor([669.5513, 270.8752]) tensor([692.6779, 270.3995])\n",
      "tensor([666.8678, 303.3241]) tensor([692.9536, 302.4560])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 235.5ms\n",
      "Speed: 2.1ms preprocess, 235.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([662.5759, 302.4701]) tensor([659.9117, 288.3740])\n",
      "tensor([691.2567, 303.0325]) tensor([695.0327, 288.6549])\n",
      "tensor([666.5345, 271.7513]) tensor([689.1674, 271.8700])\n",
      "tensor([662.5759, 302.4701]) tensor([691.2567, 303.0325])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 223.5ms\n",
      "Speed: 2.5ms preprocess, 223.5ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([565.0633, 447.9304]) tensor([572.3509, 467.8613])\n",
      "tensor([565.6339, 449.8589]) tensor([570.2624, 468.6995])\n",
      "1\n",
      "tensor([581.9907, 478.4830]) tensor([580.4359, 478.7855])\n",
      "tensor([565.0633, 447.9304]) tensor([565.6339, 449.8589])\n",
      "\n",
      "0: 384x640 2 persons, 235.1ms\n",
      "Speed: 2.0ms preprocess, 235.1ms inference, 2.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([656.2352, 306.9906]) tensor([652.8209, 291.2274])\n",
      "tensor([684.3792, 306.7284]) tensor([687.5610, 290.9374])\n",
      "tensor([659.5610, 274.1800]) tensor([682.5757, 274.0861])\n",
      "tensor([656.2352, 306.9906]) tensor([684.3792, 306.7284])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 217.0ms\n",
      "Speed: 2.0ms preprocess, 217.0ms inference, 2.2ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([574.5815, 461.3004]) tensor([579.1182, 472.0309])\n",
      "tensor([544.6614, 464.3422]) tensor([548.9976, 474.4584])\n",
      "1\n",
      "tensor([572.4583, 479.3603]) tensor([562.5799, 480.6998])\n",
      "tensor([574.5815, 461.3004]) tensor([544.6614, 464.3422])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 209.5ms\n",
      "Speed: 2.5ms preprocess, 209.5ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([567.5492, 456.7635]) tensor([568.6538, 471.3292])\n",
      "tensor([546.3184, 457.1179]) tensor([544.8658, 472.2008])\n",
      "1\n",
      "tensor([563.4765, 475.4469]) tensor([551.6522, 476.2419])\n",
      "tensor([567.5492, 456.7635]) tensor([546.3184, 457.1179])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 222.9ms\n",
      "Speed: 3.0ms preprocess, 222.9ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([554.0087, 455.0600]) tensor([554.3352, 471.0240])\n",
      "tensor([540.3617, 454.5900]) tensor([539.1246, 470.6375])\n",
      "1\n",
      "tensor([554.8578, 475.1625]) tensor([544.8865, 475.1086])\n",
      "tensor([554.0087, 455.0600]) tensor([540.3617, 454.5900])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 246.7ms\n",
      "Speed: 2.6ms preprocess, 246.7ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([548.1346, 495.1418]) tensor([551.9579, 493.8715])\n",
      "tensor([538.9091, 498.2941]) tensor([543.3784, 496.2654])\n",
      "tensor([549.2189, 478.8786]) tensor([540.9532, 480.6000])\n",
      "tensor([548.1346, 495.1418]) tensor([538.9091, 498.2941])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 244.4ms\n",
      "Speed: 2.0ms preprocess, 244.4ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([550.5699, 473.7292]) tensor([550.1918, 478.4647])\n",
      "tensor([532.7415, 466.8683]) tensor([529.7112, 476.5052])\n",
      "1\n",
      "tensor([548.3305, 471.2706]) tensor([535.3939, 471.5015])\n",
      "tensor([550.5699, 473.7292]) tensor([532.7415, 466.8683])\n",
      "2\n",
      "\n",
      "0: 384x640 2 persons, 247.2ms\n",
      "Speed: 2.0ms preprocess, 247.2ms inference, 1.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "-------\n",
      "tensor([523.2910, 494.7891]) tensor([529.3519, 496.1435])\n",
      "tensor([547.3679, 463.5442]) tensor([553.2848, 477.7711])\n",
      "1\n",
      "tensor([527.3948, 481.9544]) tensor([535.9836, 475.9720])\n",
      "tensor([523.2910, 494.7891]) tensor([547.3679, 463.5442])\n",
      "2\n",
      "count ==  66\n"
     ]
    }
   ],
   "source": [
    "import cv2  \n",
    "import os  \n",
    "model = YOLO(\"yolov8n-pose.pt\")  \n",
    "\n",
    "#判断是否是高远球姿势\n",
    "def condition_func(frame):   \n",
    "    # 进行姿态分析  \n",
    "    results = model(frame)  \n",
    "    keypoints = results[0].keypoints.xy[0]\n",
    "\n",
    "    print(\"----------------\")\n",
    "    #print(keypoints[0][1])\n",
    "    if keypoints.size(0) == 0:\n",
    "        return False\n",
    "    k = 0\n",
    "\n",
    "    #两个手的点位分别高于两个手臂的点位\n",
    "    print(keypoints[10], keypoints[8])\n",
    "    print(keypoints[9], keypoints[7])\n",
    "    if keypoints[10][1] < keypoints[8][1] and keypoints[9][1] < keypoints[7][1] :\n",
    "        print(\"1\")\n",
    "        k += 1 \n",
    "\n",
    "    #两手距离大于肩宽，手臂张开\n",
    "    print(keypoints[6], keypoints[5])\n",
    "    print(keypoints[10], keypoints[9])\n",
    "    if abs(keypoints[6][0]-keypoints[5][0]) < abs(keypoints[9][0] - keypoints[10][0]):\n",
    "        print(\"2\")\n",
    "        k += 1\n",
    "    if k==2: return True\n",
    "    else:\n",
    "        return False\n",
    "    \n",
    "  \n",
    "def process_video(video_path, output_folder, condition_func):  \n",
    "    if not os.path.exists(output_folder):  \n",
    "        os.makedirs(output_folder)  \n",
    "  \n",
    "    cap = cv2.VideoCapture(video_path)  \n",
    "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))  \n",
    "    frame_idx = 0  \n",
    "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # 输出视频编码格式  \n",
    "    out = None  # 初始化视频写入对象  \n",
    "    start_idx = -1  # 初始化满足条件的帧序列的开始索引  \n",
    "    while cap.isOpened():  \n",
    "        ret, frame = cap.read()  \n",
    "        if not ret:  \n",
    "            break  \n",
    "  \n",
    "        if condition_func(frame):  \n",
    "            # 保存当前帧为图片  \n",
    "            frame_filename = os.path.join(output_folder, f\"frame_{frame_idx:06d}.png\")  \n",
    "            cv2.imwrite(frame_filename, frame)  \n",
    "            print(f\"Saved frame {frame_idx} as {frame_filename}\")  \n",
    "        #     if start_idx == -1:  # 如果这是序列的开始，则创建新的视频写入对象  \n",
    "        #         start_idx = frame_idx  \n",
    "        #         out_filename = os.path.join(output_folder, f\"clip_{frame_idx//1000:04d}.mp4\")  # 使用帧索引（或时间戳）来命名文件  \n",
    "        #         out = cv2.VideoWriter(out_filename, fourcc, cap.get(cv2.CAP_PROP_FPS), (int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))))  \n",
    "  \n",
    "        #     # 写入当前帧到视频  \n",
    "        #     out.write(frame)  \n",
    "        # else:  \n",
    "        #     if start_idx != -1:  # 如果之前有一个满足条件的序列，现在结束了  \n",
    "        #         out.release()  # 释放当前视频写入对象  \n",
    "        #         out = None  \n",
    "        #         start_idx = -1  # 重置开始索引  \n",
    "  \n",
    "        frame_idx += 1  \n",
    "  \n",
    "    # 如果在处理结束时有一个未完成的序列，确保它被保存  \n",
    "    if out is not None:  \n",
    "        out.release()  \n",
    "    cap.release()  \n",
    "  \n",
    "# 调用函数处理视频  \n",
    "video_path = \"badminton.mp4\"  # 替换为你的视频文件路径  \n",
    "output_folder = \"output_clips\"  # 输出文件夹  \n",
    "process_video(video_path, output_folder, condition_func)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Environment does not support cv2.imshow() or PIL Image.show()\n",
      "OpenCV(4.10.0) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\highgui\\src\\window.cpp:1301: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
      "\n",
      "\n",
      "\n",
      "WARNING  inference results will accumulate in RAM unless `stream=True` is passed, causing potential out-of-memory\n",
      "errors for large sources or long-running streams and videos. See https://docs.ultralytics.com/modes/predict/ for help.\n",
      "\n",
      "Example:\n",
      "    results = model(source=..., stream=True)  # generator of Results objects\n",
      "    for r in results:\n",
      "        boxes = r.boxes  # Boxes object for bbox outputs\n",
      "        masks = r.masks  # Masks object for segment masks outputs\n",
      "        probs = r.probs  # Class probabilities for classification outputs\n",
      "\n",
      "video 1/1 (frame 1/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 294.0ms\n",
      "video 1/1 (frame 2/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 212.0ms\n",
      "video 1/1 (frame 3/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 228.7ms\n",
      "video 1/1 (frame 4/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 195.2ms\n",
      "video 1/1 (frame 5/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 188.2ms\n",
      "video 1/1 (frame 6/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 182.4ms\n",
      "video 1/1 (frame 7/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 150.7ms\n",
      "video 1/1 (frame 8/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 9/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.1ms\n",
      "video 1/1 (frame 10/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.0ms\n",
      "video 1/1 (frame 11/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.1ms\n",
      "video 1/1 (frame 12/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.3ms\n",
      "video 1/1 (frame 13/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.7ms\n",
      "video 1/1 (frame 14/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.6ms\n",
      "video 1/1 (frame 15/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 16/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.6ms\n",
      "video 1/1 (frame 17/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.5ms\n",
      "video 1/1 (frame 18/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.5ms\n",
      "video 1/1 (frame 19/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 169.2ms\n",
      "video 1/1 (frame 20/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 21/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.8ms\n",
      "video 1/1 (frame 22/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.7ms\n",
      "video 1/1 (frame 23/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 24/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.3ms\n",
      "video 1/1 (frame 25/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.8ms\n",
      "video 1/1 (frame 26/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.5ms\n",
      "video 1/1 (frame 27/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 28/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.5ms\n",
      "video 1/1 (frame 29/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.5ms\n",
      "video 1/1 (frame 30/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.4ms\n",
      "video 1/1 (frame 31/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.5ms\n",
      "video 1/1 (frame 32/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.8ms\n",
      "video 1/1 (frame 33/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 34/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.6ms\n",
      "video 1/1 (frame 35/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.8ms\n",
      "video 1/1 (frame 36/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 37/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 38/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.4ms\n",
      "video 1/1 (frame 39/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.6ms\n",
      "video 1/1 (frame 40/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 41/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 42/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 43/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.3ms\n",
      "video 1/1 (frame 44/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.3ms\n",
      "video 1/1 (frame 45/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.3ms\n",
      "video 1/1 (frame 46/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 47/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 48/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.3ms\n",
      "video 1/1 (frame 49/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.4ms\n",
      "video 1/1 (frame 50/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 51/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 52/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 53/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.6ms\n",
      "video 1/1 (frame 54/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 55/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.6ms\n",
      "video 1/1 (frame 56/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.0ms\n",
      "video 1/1 (frame 57/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.5ms\n",
      "video 1/1 (frame 58/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 59/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.4ms\n",
      "video 1/1 (frame 60/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 61/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 62/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.8ms\n",
      "video 1/1 (frame 63/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 64/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 65/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.6ms\n",
      "video 1/1 (frame 66/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 67/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.1ms\n",
      "video 1/1 (frame 68/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 69/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 70/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 71/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.9ms\n",
      "video 1/1 (frame 72/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 73/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 74/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.2ms\n",
      "video 1/1 (frame 75/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 76/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 77/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.6ms\n",
      "video 1/1 (frame 78/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 133.4ms\n",
      "video 1/1 (frame 79/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.5ms\n",
      "video 1/1 (frame 80/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 148.6ms\n",
      "video 1/1 (frame 81/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 130.4ms\n",
      "video 1/1 (frame 82/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 133.9ms\n",
      "video 1/1 (frame 83/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.4ms\n",
      "video 1/1 (frame 84/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.1ms\n",
      "video 1/1 (frame 85/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.1ms\n",
      "video 1/1 (frame 86/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 133.6ms\n",
      "video 1/1 (frame 87/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.9ms\n",
      "video 1/1 (frame 88/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.7ms\n",
      "video 1/1 (frame 89/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.7ms\n",
      "video 1/1 (frame 90/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.6ms\n",
      "video 1/1 (frame 91/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.5ms\n",
      "video 1/1 (frame 92/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.1ms\n",
      "video 1/1 (frame 93/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 142.4ms\n",
      "video 1/1 (frame 94/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 143.2ms\n",
      "video 1/1 (frame 95/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.5ms\n",
      "video 1/1 (frame 96/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.2ms\n",
      "video 1/1 (frame 97/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 131.7ms\n",
      "video 1/1 (frame 98/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.5ms\n",
      "video 1/1 (frame 99/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 147.5ms\n",
      "video 1/1 (frame 100/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 129.2ms\n",
      "video 1/1 (frame 101/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 128.8ms\n",
      "video 1/1 (frame 102/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 103/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.1ms\n",
      "video 1/1 (frame 104/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 105/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.6ms\n",
      "video 1/1 (frame 106/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.8ms\n",
      "video 1/1 (frame 107/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.4ms\n",
      "video 1/1 (frame 108/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.4ms\n",
      "video 1/1 (frame 109/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 110/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 111/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.0ms\n",
      "video 1/1 (frame 112/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 113/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.4ms\n",
      "video 1/1 (frame 114/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.4ms\n",
      "video 1/1 (frame 115/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.3ms\n",
      "video 1/1 (frame 116/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.0ms\n",
      "video 1/1 (frame 117/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 156.0ms\n",
      "video 1/1 (frame 118/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.3ms\n",
      "video 1/1 (frame 119/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 146.5ms\n",
      "video 1/1 (frame 120/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 142.5ms\n",
      "video 1/1 (frame 121/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 144.1ms\n",
      "video 1/1 (frame 122/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.2ms\n",
      "video 1/1 (frame 123/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.3ms\n",
      "video 1/1 (frame 124/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 125/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.6ms\n",
      "video 1/1 (frame 126/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 165.7ms\n",
      "video 1/1 (frame 127/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.5ms\n",
      "video 1/1 (frame 128/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 129/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 130/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 209.9ms\n",
      "video 1/1 (frame 131/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 169.4ms\n",
      "video 1/1 (frame 132/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 187.9ms\n",
      "video 1/1 (frame 133/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.7ms\n",
      "video 1/1 (frame 134/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.2ms\n",
      "video 1/1 (frame 135/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 136/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 137/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.8ms\n",
      "video 1/1 (frame 138/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.9ms\n",
      "video 1/1 (frame 139/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.8ms\n",
      "video 1/1 (frame 140/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.7ms\n",
      "video 1/1 (frame 141/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 142/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.5ms\n",
      "video 1/1 (frame 143/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 144/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 145/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 146/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 147/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.2ms\n",
      "video 1/1 (frame 148/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.7ms\n",
      "video 1/1 (frame 149/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.0ms\n",
      "video 1/1 (frame 150/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.4ms\n",
      "video 1/1 (frame 151/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.5ms\n",
      "video 1/1 (frame 152/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.7ms\n",
      "video 1/1 (frame 153/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.8ms\n",
      "video 1/1 (frame 154/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.1ms\n",
      "video 1/1 (frame 155/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 158.1ms\n",
      "video 1/1 (frame 156/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 157/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 157.6ms\n",
      "video 1/1 (frame 158/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.4ms\n",
      "video 1/1 (frame 159/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.5ms\n",
      "video 1/1 (frame 160/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.6ms\n",
      "video 1/1 (frame 161/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 162/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 163/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 164/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.5ms\n",
      "video 1/1 (frame 165/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.9ms\n",
      "video 1/1 (frame 166/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.7ms\n",
      "video 1/1 (frame 167/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.3ms\n",
      "video 1/1 (frame 168/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.4ms\n",
      "video 1/1 (frame 169/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 170/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 164.8ms\n",
      "video 1/1 (frame 171/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 172/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 173/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.7ms\n",
      "video 1/1 (frame 174/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.9ms\n",
      "video 1/1 (frame 175/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.0ms\n",
      "video 1/1 (frame 176/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 177/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.4ms\n",
      "video 1/1 (frame 178/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.2ms\n",
      "video 1/1 (frame 179/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.7ms\n",
      "video 1/1 (frame 180/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.6ms\n",
      "video 1/1 (frame 181/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 182/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.8ms\n",
      "video 1/1 (frame 183/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.8ms\n",
      "video 1/1 (frame 184/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 185/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.8ms\n",
      "video 1/1 (frame 186/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.4ms\n",
      "video 1/1 (frame 187/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.1ms\n",
      "video 1/1 (frame 188/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 189/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.9ms\n",
      "video 1/1 (frame 190/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.7ms\n",
      "video 1/1 (frame 191/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.2ms\n",
      "video 1/1 (frame 192/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.3ms\n",
      "video 1/1 (frame 193/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.4ms\n",
      "video 1/1 (frame 194/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 195/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.7ms\n",
      "video 1/1 (frame 196/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.4ms\n",
      "video 1/1 (frame 197/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 173.1ms\n",
      "video 1/1 (frame 198/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 199/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.0ms\n",
      "video 1/1 (frame 200/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.7ms\n",
      "video 1/1 (frame 201/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.5ms\n",
      "video 1/1 (frame 202/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.4ms\n",
      "video 1/1 (frame 203/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 204/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.9ms\n",
      "video 1/1 (frame 205/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.5ms\n",
      "video 1/1 (frame 206/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 150.7ms\n",
      "video 1/1 (frame 207/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.0ms\n",
      "video 1/1 (frame 208/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.3ms\n",
      "video 1/1 (frame 209/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.6ms\n",
      "video 1/1 (frame 210/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.9ms\n",
      "video 1/1 (frame 211/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 212/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.2ms\n",
      "video 1/1 (frame 213/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 214/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.8ms\n",
      "video 1/1 (frame 215/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.0ms\n",
      "video 1/1 (frame 216/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.7ms\n",
      "video 1/1 (frame 217/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.6ms\n",
      "video 1/1 (frame 218/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 154.2ms\n",
      "video 1/1 (frame 219/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.8ms\n",
      "video 1/1 (frame 220/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.3ms\n",
      "video 1/1 (frame 221/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 222/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.5ms\n",
      "video 1/1 (frame 223/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 224/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.4ms\n",
      "video 1/1 (frame 225/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 226/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.3ms\n",
      "video 1/1 (frame 227/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 228/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 229/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 127.8ms\n",
      "video 1/1 (frame 230/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 126.4ms\n",
      "video 1/1 (frame 231/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.3ms\n",
      "video 1/1 (frame 232/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.3ms\n",
      "video 1/1 (frame 233/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.1ms\n",
      "video 1/1 (frame 234/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 235/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.3ms\n",
      "video 1/1 (frame 236/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.7ms\n",
      "video 1/1 (frame 237/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.0ms\n",
      "video 1/1 (frame 238/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 239/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 240/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.4ms\n",
      "video 1/1 (frame 241/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.8ms\n",
      "video 1/1 (frame 242/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.6ms\n",
      "video 1/1 (frame 243/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 244/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.9ms\n",
      "video 1/1 (frame 245/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 246/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 127.2ms\n",
      "video 1/1 (frame 247/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.0ms\n",
      "video 1/1 (frame 248/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.9ms\n",
      "video 1/1 (frame 249/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 250/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.0ms\n",
      "video 1/1 (frame 251/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 252/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.2ms\n",
      "video 1/1 (frame 253/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.9ms\n",
      "video 1/1 (frame 254/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.2ms\n",
      "video 1/1 (frame 255/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.4ms\n",
      "video 1/1 (frame 256/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.8ms\n",
      "video 1/1 (frame 257/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 258/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.0ms\n",
      "video 1/1 (frame 259/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.5ms\n",
      "video 1/1 (frame 260/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.4ms\n",
      "video 1/1 (frame 261/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 262/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.5ms\n",
      "video 1/1 (frame 263/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.5ms\n",
      "video 1/1 (frame 264/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.8ms\n",
      "video 1/1 (frame 265/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.3ms\n",
      "video 1/1 (frame 266/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 267/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.8ms\n",
      "video 1/1 (frame 268/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 269/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.5ms\n",
      "video 1/1 (frame 270/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.2ms\n",
      "video 1/1 (frame 271/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.4ms\n",
      "video 1/1 (frame 272/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 273/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.7ms\n",
      "video 1/1 (frame 274/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.7ms\n",
      "video 1/1 (frame 275/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 276/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 277/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 278/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.7ms\n",
      "video 1/1 (frame 279/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 280/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 281/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.1ms\n",
      "video 1/1 (frame 282/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 283/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.5ms\n",
      "video 1/1 (frame 284/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 285/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.9ms\n",
      "video 1/1 (frame 286/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.5ms\n",
      "video 1/1 (frame 287/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 288/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.9ms\n",
      "video 1/1 (frame 289/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.3ms\n",
      "video 1/1 (frame 290/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 291/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 292/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.3ms\n",
      "video 1/1 (frame 293/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.2ms\n",
      "video 1/1 (frame 294/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 295/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 296/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.5ms\n",
      "video 1/1 (frame 297/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.0ms\n",
      "video 1/1 (frame 298/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.0ms\n",
      "video 1/1 (frame 299/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 300/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.2ms\n",
      "video 1/1 (frame 301/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 302/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 136.2ms\n",
      "video 1/1 (frame 303/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.5ms\n",
      "video 1/1 (frame 304/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.9ms\n",
      "video 1/1 (frame 305/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.4ms\n",
      "video 1/1 (frame 306/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.7ms\n",
      "video 1/1 (frame 307/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.7ms\n",
      "video 1/1 (frame 308/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.5ms\n",
      "video 1/1 (frame 309/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 145.7ms\n",
      "video 1/1 (frame 310/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.2ms\n",
      "video 1/1 (frame 311/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.8ms\n",
      "video 1/1 (frame 312/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 129.2ms\n",
      "video 1/1 (frame 313/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 126.6ms\n",
      "video 1/1 (frame 314/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 128.1ms\n",
      "video 1/1 (frame 315/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.3ms\n",
      "video 1/1 (frame 316/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.1ms\n",
      "video 1/1 (frame 317/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 133.3ms\n",
      "video 1/1 (frame 318/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.0ms\n",
      "video 1/1 (frame 319/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.8ms\n",
      "video 1/1 (frame 320/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 154.2ms\n",
      "video 1/1 (frame 321/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 154.4ms\n",
      "video 1/1 (frame 322/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.9ms\n",
      "video 1/1 (frame 323/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.2ms\n",
      "video 1/1 (frame 324/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.2ms\n",
      "video 1/1 (frame 325/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 144.4ms\n",
      "video 1/1 (frame 326/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.1ms\n",
      "video 1/1 (frame 327/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.5ms\n",
      "video 1/1 (frame 328/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.6ms\n",
      "video 1/1 (frame 329/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.3ms\n",
      "video 1/1 (frame 330/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.0ms\n",
      "video 1/1 (frame 331/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.0ms\n",
      "video 1/1 (frame 332/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.7ms\n",
      "video 1/1 (frame 333/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.1ms\n",
      "video 1/1 (frame 334/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 149.8ms\n",
      "video 1/1 (frame 335/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.9ms\n",
      "video 1/1 (frame 336/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.4ms\n",
      "video 1/1 (frame 337/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.3ms\n",
      "video 1/1 (frame 338/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 132.0ms\n",
      "video 1/1 (frame 339/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 130.5ms\n",
      "video 1/1 (frame 340/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.4ms\n",
      "video 1/1 (frame 341/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.7ms\n",
      "video 1/1 (frame 342/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.0ms\n",
      "video 1/1 (frame 343/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.4ms\n",
      "video 1/1 (frame 344/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 131.4ms\n",
      "video 1/1 (frame 345/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.1ms\n",
      "video 1/1 (frame 346/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 130.7ms\n",
      "video 1/1 (frame 347/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.5ms\n",
      "video 1/1 (frame 348/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 143.1ms\n",
      "video 1/1 (frame 349/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.4ms\n",
      "video 1/1 (frame 350/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.7ms\n",
      "video 1/1 (frame 351/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.3ms\n",
      "video 1/1 (frame 352/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.9ms\n",
      "video 1/1 (frame 353/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.4ms\n",
      "video 1/1 (frame 354/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 129.7ms\n",
      "video 1/1 (frame 355/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.4ms\n",
      "video 1/1 (frame 356/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 131.9ms\n",
      "video 1/1 (frame 357/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 130.2ms\n",
      "video 1/1 (frame 358/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 132.3ms\n",
      "video 1/1 (frame 359/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 126.4ms\n",
      "video 1/1 (frame 360/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 127.5ms\n",
      "video 1/1 (frame 361/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.0ms\n",
      "video 1/1 (frame 362/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 132.9ms\n",
      "video 1/1 (frame 363/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 130.3ms\n",
      "video 1/1 (frame 364/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 129.2ms\n",
      "video 1/1 (frame 365/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.2ms\n",
      "video 1/1 (frame 366/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.4ms\n",
      "video 1/1 (frame 367/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.4ms\n",
      "video 1/1 (frame 368/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 126.8ms\n",
      "video 1/1 (frame 369/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 144.7ms\n",
      "video 1/1 (frame 370/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.4ms\n",
      "video 1/1 (frame 371/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.0ms\n",
      "video 1/1 (frame 372/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 132.6ms\n",
      "video 1/1 (frame 373/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 132.9ms\n",
      "video 1/1 (frame 374/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.3ms\n",
      "video 1/1 (frame 375/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.5ms\n",
      "video 1/1 (frame 376/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.0ms\n",
      "video 1/1 (frame 377/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.2ms\n",
      "video 1/1 (frame 378/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.8ms\n",
      "video 1/1 (frame 379/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 142.0ms\n",
      "video 1/1 (frame 380/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.2ms\n",
      "video 1/1 (frame 381/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 143.4ms\n",
      "video 1/1 (frame 382/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.9ms\n",
      "video 1/1 (frame 383/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 147.4ms\n",
      "video 1/1 (frame 384/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 144.1ms\n",
      "video 1/1 (frame 385/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.8ms\n",
      "video 1/1 (frame 386/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.9ms\n",
      "video 1/1 (frame 387/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.8ms\n",
      "video 1/1 (frame 388/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.3ms\n",
      "video 1/1 (frame 389/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.7ms\n",
      "video 1/1 (frame 390/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 133.6ms\n",
      "video 1/1 (frame 391/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 143.3ms\n",
      "video 1/1 (frame 392/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 145.2ms\n",
      "video 1/1 (frame 393/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 143.3ms\n",
      "video 1/1 (frame 394/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.9ms\n",
      "video 1/1 (frame 395/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.7ms\n",
      "video 1/1 (frame 396/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 143.4ms\n",
      "video 1/1 (frame 397/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.6ms\n",
      "video 1/1 (frame 398/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.5ms\n",
      "video 1/1 (frame 399/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.0ms\n",
      "video 1/1 (frame 400/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.4ms\n",
      "video 1/1 (frame 401/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.4ms\n",
      "video 1/1 (frame 402/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 144.7ms\n",
      "video 1/1 (frame 403/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.6ms\n",
      "video 1/1 (frame 404/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 144.5ms\n",
      "video 1/1 (frame 405/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.0ms\n",
      "video 1/1 (frame 406/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.5ms\n",
      "video 1/1 (frame 407/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 142.6ms\n",
      "video 1/1 (frame 408/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 129.8ms\n",
      "video 1/1 (frame 409/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 132.6ms\n",
      "video 1/1 (frame 410/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 133.9ms\n",
      "video 1/1 (frame 411/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.6ms\n",
      "video 1/1 (frame 412/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.1ms\n",
      "video 1/1 (frame 413/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 133.6ms\n",
      "video 1/1 (frame 414/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 135.4ms\n",
      "video 1/1 (frame 415/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.0ms\n",
      "video 1/1 (frame 416/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 417/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 418/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 419/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.6ms\n",
      "video 1/1 (frame 420/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.7ms\n",
      "video 1/1 (frame 421/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.9ms\n",
      "video 1/1 (frame 422/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.0ms\n",
      "video 1/1 (frame 423/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 424/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.4ms\n",
      "video 1/1 (frame 425/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.0ms\n",
      "video 1/1 (frame 426/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.4ms\n",
      "video 1/1 (frame 427/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 428/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.0ms\n",
      "video 1/1 (frame 429/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.3ms\n",
      "video 1/1 (frame 430/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.0ms\n",
      "video 1/1 (frame 431/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 432/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 433/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 434/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.4ms\n",
      "video 1/1 (frame 435/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 436/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 437/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.8ms\n",
      "video 1/1 (frame 438/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.7ms\n",
      "video 1/1 (frame 439/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.6ms\n",
      "video 1/1 (frame 440/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 441/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.1ms\n",
      "video 1/1 (frame 442/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 165.7ms\n",
      "video 1/1 (frame 443/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.6ms\n",
      "video 1/1 (frame 444/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 445/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 446/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.8ms\n",
      "video 1/1 (frame 447/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 448/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 155.8ms\n",
      "video 1/1 (frame 449/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 450/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 451/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 452/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 453/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.4ms\n",
      "video 1/1 (frame 454/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 455/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.3ms\n",
      "video 1/1 (frame 456/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 457/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 158.2ms\n",
      "video 1/1 (frame 458/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 459/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.3ms\n",
      "video 1/1 (frame 460/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.3ms\n",
      "video 1/1 (frame 461/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.8ms\n",
      "video 1/1 (frame 462/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.0ms\n",
      "video 1/1 (frame 463/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.5ms\n",
      "video 1/1 (frame 464/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 465/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.4ms\n",
      "video 1/1 (frame 466/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.1ms\n",
      "video 1/1 (frame 467/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.7ms\n",
      "video 1/1 (frame 468/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.1ms\n",
      "video 1/1 (frame 469/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 470/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 471/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 472/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.6ms\n",
      "video 1/1 (frame 473/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 474/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 475/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.5ms\n",
      "video 1/1 (frame 476/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.0ms\n",
      "video 1/1 (frame 477/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.9ms\n",
      "video 1/1 (frame 478/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 479/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.1ms\n",
      "video 1/1 (frame 480/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 481/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 482/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.1ms\n",
      "video 1/1 (frame 483/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.3ms\n",
      "video 1/1 (frame 484/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.1ms\n",
      "video 1/1 (frame 485/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 486/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.7ms\n",
      "video 1/1 (frame 487/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 488/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.7ms\n",
      "video 1/1 (frame 489/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.1ms\n",
      "video 1/1 (frame 490/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.5ms\n",
      "video 1/1 (frame 491/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.6ms\n",
      "video 1/1 (frame 492/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.0ms\n",
      "video 1/1 (frame 493/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.7ms\n",
      "video 1/1 (frame 494/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.5ms\n",
      "video 1/1 (frame 495/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 150.7ms\n",
      "video 1/1 (frame 496/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.5ms\n",
      "video 1/1 (frame 497/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 498/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 167.6ms\n",
      "video 1/1 (frame 499/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 500/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.1ms\n",
      "video 1/1 (frame 501/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.6ms\n",
      "video 1/1 (frame 502/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 503/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.0ms\n",
      "video 1/1 (frame 504/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.1ms\n",
      "video 1/1 (frame 505/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.6ms\n",
      "video 1/1 (frame 506/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 507/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.5ms\n",
      "video 1/1 (frame 508/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.9ms\n",
      "video 1/1 (frame 509/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.6ms\n",
      "video 1/1 (frame 510/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.7ms\n",
      "video 1/1 (frame 511/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.9ms\n",
      "video 1/1 (frame 512/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.4ms\n",
      "video 1/1 (frame 513/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.7ms\n",
      "video 1/1 (frame 514/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 515/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.3ms\n",
      "video 1/1 (frame 516/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 517/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 518/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.3ms\n",
      "video 1/1 (frame 519/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.5ms\n",
      "video 1/1 (frame 520/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 521/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.5ms\n",
      "video 1/1 (frame 522/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.1ms\n",
      "video 1/1 (frame 523/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.4ms\n",
      "video 1/1 (frame 524/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 525/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.6ms\n",
      "video 1/1 (frame 526/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 527/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 528/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.0ms\n",
      "video 1/1 (frame 529/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.5ms\n",
      "video 1/1 (frame 530/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.5ms\n",
      "video 1/1 (frame 531/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.6ms\n",
      "video 1/1 (frame 532/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 533/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.4ms\n",
      "video 1/1 (frame 534/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.3ms\n",
      "video 1/1 (frame 535/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.1ms\n",
      "video 1/1 (frame 536/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.1ms\n",
      "video 1/1 (frame 537/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 538/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.7ms\n",
      "video 1/1 (frame 539/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.5ms\n",
      "video 1/1 (frame 540/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 541/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 542/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 543/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 155.9ms\n",
      "video 1/1 (frame 544/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.7ms\n",
      "video 1/1 (frame 545/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 546/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 171.3ms\n",
      "video 1/1 (frame 547/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.8ms\n",
      "video 1/1 (frame 548/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.6ms\n",
      "video 1/1 (frame 549/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.7ms\n",
      "video 1/1 (frame 550/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.0ms\n",
      "video 1/1 (frame 551/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 552/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.5ms\n",
      "video 1/1 (frame 553/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.8ms\n",
      "video 1/1 (frame 554/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.4ms\n",
      "video 1/1 (frame 555/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 155.6ms\n",
      "video 1/1 (frame 556/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.2ms\n",
      "video 1/1 (frame 557/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.4ms\n",
      "video 1/1 (frame 558/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.3ms\n",
      "video 1/1 (frame 559/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.1ms\n",
      "video 1/1 (frame 560/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.0ms\n",
      "video 1/1 (frame 561/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.1ms\n",
      "video 1/1 (frame 562/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.4ms\n",
      "video 1/1 (frame 563/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.0ms\n",
      "video 1/1 (frame 564/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.3ms\n",
      "video 1/1 (frame 565/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.8ms\n",
      "video 1/1 (frame 566/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.4ms\n",
      "video 1/1 (frame 567/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.4ms\n",
      "video 1/1 (frame 568/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.7ms\n",
      "video 1/1 (frame 569/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 570/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.6ms\n",
      "video 1/1 (frame 571/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.3ms\n",
      "video 1/1 (frame 572/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.4ms\n",
      "video 1/1 (frame 573/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.0ms\n",
      "video 1/1 (frame 574/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.1ms\n",
      "video 1/1 (frame 575/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.6ms\n",
      "video 1/1 (frame 576/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.6ms\n",
      "video 1/1 (frame 577/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.6ms\n",
      "video 1/1 (frame 578/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.1ms\n",
      "video 1/1 (frame 579/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 580/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.5ms\n",
      "video 1/1 (frame 581/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.6ms\n",
      "video 1/1 (frame 582/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 583/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 584/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 585/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 586/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.7ms\n",
      "video 1/1 (frame 587/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.8ms\n",
      "video 1/1 (frame 588/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.7ms\n",
      "video 1/1 (frame 589/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 590/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.2ms\n",
      "video 1/1 (frame 591/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 592/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.8ms\n",
      "video 1/1 (frame 593/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.5ms\n",
      "video 1/1 (frame 594/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.6ms\n",
      "video 1/1 (frame 595/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.5ms\n",
      "video 1/1 (frame 596/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 160.9ms\n",
      "video 1/1 (frame 597/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.5ms\n",
      "video 1/1 (frame 598/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 599/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.7ms\n",
      "video 1/1 (frame 600/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 601/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.7ms\n",
      "video 1/1 (frame 602/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 603/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.7ms\n",
      "video 1/1 (frame 604/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.7ms\n",
      "video 1/1 (frame 605/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.1ms\n",
      "video 1/1 (frame 606/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.0ms\n",
      "video 1/1 (frame 607/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 608/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.7ms\n",
      "video 1/1 (frame 609/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 610/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.6ms\n",
      "video 1/1 (frame 611/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.7ms\n",
      "video 1/1 (frame 612/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.3ms\n",
      "video 1/1 (frame 613/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 614/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.0ms\n",
      "video 1/1 (frame 615/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.1ms\n",
      "video 1/1 (frame 616/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.6ms\n",
      "video 1/1 (frame 617/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.4ms\n",
      "video 1/1 (frame 618/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 619/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 620/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.8ms\n",
      "video 1/1 (frame 621/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.7ms\n",
      "video 1/1 (frame 622/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.8ms\n",
      "video 1/1 (frame 623/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 158.9ms\n",
      "video 1/1 (frame 624/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 126.7ms\n",
      "video 1/1 (frame 625/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.3ms\n",
      "video 1/1 (frame 626/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.1ms\n",
      "video 1/1 (frame 627/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.2ms\n",
      "video 1/1 (frame 628/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.3ms\n",
      "video 1/1 (frame 629/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.4ms\n",
      "video 1/1 (frame 630/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.0ms\n",
      "video 1/1 (frame 631/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 632/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 633/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.3ms\n",
      "video 1/1 (frame 634/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 635/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.1ms\n",
      "video 1/1 (frame 636/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.6ms\n",
      "video 1/1 (frame 637/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 158.7ms\n",
      "video 1/1 (frame 638/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.0ms\n",
      "video 1/1 (frame 639/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.9ms\n",
      "video 1/1 (frame 640/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.1ms\n",
      "video 1/1 (frame 641/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.5ms\n",
      "video 1/1 (frame 642/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.1ms\n",
      "video 1/1 (frame 643/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.3ms\n",
      "video 1/1 (frame 644/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.4ms\n",
      "video 1/1 (frame 645/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.7ms\n",
      "video 1/1 (frame 646/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 647/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.3ms\n",
      "video 1/1 (frame 648/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.1ms\n",
      "video 1/1 (frame 649/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.2ms\n",
      "video 1/1 (frame 650/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 651/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.0ms\n",
      "video 1/1 (frame 652/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 653/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 654/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 655/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 656/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 657/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.5ms\n",
      "video 1/1 (frame 658/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 659/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.6ms\n",
      "video 1/1 (frame 660/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.5ms\n",
      "video 1/1 (frame 661/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 188.5ms\n",
      "video 1/1 (frame 662/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 663/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 664/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.6ms\n",
      "video 1/1 (frame 665/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.9ms\n",
      "video 1/1 (frame 666/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 667/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.6ms\n",
      "video 1/1 (frame 668/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 669/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 157.0ms\n",
      "video 1/1 (frame 670/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.6ms\n",
      "video 1/1 (frame 671/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.3ms\n",
      "video 1/1 (frame 672/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.2ms\n",
      "video 1/1 (frame 673/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 674/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.0ms\n",
      "video 1/1 (frame 675/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.7ms\n",
      "video 1/1 (frame 676/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 677/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 678/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.2ms\n",
      "video 1/1 (frame 679/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 150.6ms\n",
      "video 1/1 (frame 680/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 681/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.6ms\n",
      "video 1/1 (frame 682/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.7ms\n",
      "video 1/1 (frame 683/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 684/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.2ms\n",
      "video 1/1 (frame 685/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.6ms\n",
      "video 1/1 (frame 686/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 687/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 190.9ms\n",
      "video 1/1 (frame 688/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.0ms\n",
      "video 1/1 (frame 689/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.6ms\n",
      "video 1/1 (frame 690/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.9ms\n",
      "video 1/1 (frame 691/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 692/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 693/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 694/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 695/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 696/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.6ms\n",
      "video 1/1 (frame 697/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 698/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.3ms\n",
      "video 1/1 (frame 699/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 700/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.3ms\n",
      "video 1/1 (frame 701/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 702/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.3ms\n",
      "video 1/1 (frame 703/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 704/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 705/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.9ms\n",
      "video 1/1 (frame 706/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 707/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 708/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.1ms\n",
      "video 1/1 (frame 709/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.2ms\n",
      "video 1/1 (frame 710/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.7ms\n",
      "video 1/1 (frame 711/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.4ms\n",
      "video 1/1 (frame 712/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 713/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 714/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.6ms\n",
      "video 1/1 (frame 715/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.0ms\n",
      "video 1/1 (frame 716/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 717/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.8ms\n",
      "video 1/1 (frame 718/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.5ms\n",
      "video 1/1 (frame 719/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.2ms\n",
      "video 1/1 (frame 720/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.3ms\n",
      "video 1/1 (frame 721/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.3ms\n",
      "video 1/1 (frame 722/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.2ms\n",
      "video 1/1 (frame 723/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.4ms\n",
      "video 1/1 (frame 724/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 725/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.7ms\n",
      "video 1/1 (frame 726/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.7ms\n",
      "video 1/1 (frame 727/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.5ms\n",
      "video 1/1 (frame 728/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 729/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.2ms\n",
      "video 1/1 (frame 730/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.9ms\n",
      "video 1/1 (frame 731/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.4ms\n",
      "video 1/1 (frame 732/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.0ms\n",
      "video 1/1 (frame 733/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.9ms\n",
      "video 1/1 (frame 734/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.1ms\n",
      "video 1/1 (frame 735/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.2ms\n",
      "video 1/1 (frame 736/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.6ms\n",
      "video 1/1 (frame 737/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.2ms\n",
      "video 1/1 (frame 738/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 159.6ms\n",
      "video 1/1 (frame 739/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.0ms\n",
      "video 1/1 (frame 740/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 741/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 742/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.3ms\n",
      "video 1/1 (frame 743/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.9ms\n",
      "video 1/1 (frame 744/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.0ms\n",
      "video 1/1 (frame 745/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 746/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.6ms\n",
      "video 1/1 (frame 747/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.4ms\n",
      "video 1/1 (frame 748/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.0ms\n",
      "video 1/1 (frame 749/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 750/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 751/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.0ms\n",
      "video 1/1 (frame 752/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.4ms\n",
      "video 1/1 (frame 753/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 155.0ms\n",
      "video 1/1 (frame 754/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.5ms\n",
      "video 1/1 (frame 755/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.5ms\n",
      "video 1/1 (frame 756/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.3ms\n",
      "video 1/1 (frame 757/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 758/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.1ms\n",
      "video 1/1 (frame 759/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.7ms\n",
      "video 1/1 (frame 760/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.9ms\n",
      "video 1/1 (frame 761/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.7ms\n",
      "video 1/1 (frame 762/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 763/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.7ms\n",
      "video 1/1 (frame 764/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.6ms\n",
      "video 1/1 (frame 765/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.9ms\n",
      "video 1/1 (frame 766/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.0ms\n",
      "video 1/1 (frame 767/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.5ms\n",
      "video 1/1 (frame 768/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.6ms\n",
      "video 1/1 (frame 769/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 770/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.8ms\n",
      "video 1/1 (frame 771/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.3ms\n",
      "video 1/1 (frame 772/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.7ms\n",
      "video 1/1 (frame 773/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.6ms\n",
      "video 1/1 (frame 774/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 775/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 776/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 777/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 778/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.9ms\n",
      "video 1/1 (frame 779/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 150.2ms\n",
      "video 1/1 (frame 780/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 781/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 782/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 783/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.2ms\n",
      "video 1/1 (frame 784/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.5ms\n",
      "video 1/1 (frame 785/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.9ms\n",
      "video 1/1 (frame 786/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.6ms\n",
      "video 1/1 (frame 787/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.3ms\n",
      "video 1/1 (frame 788/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 789/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 160.2ms\n",
      "video 1/1 (frame 790/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.5ms\n",
      "video 1/1 (frame 791/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.5ms\n",
      "video 1/1 (frame 792/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.5ms\n",
      "video 1/1 (frame 793/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.7ms\n",
      "video 1/1 (frame 794/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.4ms\n",
      "video 1/1 (frame 795/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 133.8ms\n",
      "video 1/1 (frame 796/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 797/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.1ms\n",
      "video 1/1 (frame 798/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.4ms\n",
      "video 1/1 (frame 799/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.7ms\n",
      "video 1/1 (frame 800/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 126.9ms\n",
      "video 1/1 (frame 801/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 802/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.7ms\n",
      "video 1/1 (frame 803/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.9ms\n",
      "video 1/1 (frame 804/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.6ms\n",
      "video 1/1 (frame 805/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.7ms\n",
      "video 1/1 (frame 806/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.8ms\n",
      "video 1/1 (frame 807/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.6ms\n",
      "video 1/1 (frame 808/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 809/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.9ms\n",
      "video 1/1 (frame 810/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.7ms\n",
      "video 1/1 (frame 811/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.1ms\n",
      "video 1/1 (frame 812/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.2ms\n",
      "video 1/1 (frame 813/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.4ms\n",
      "video 1/1 (frame 814/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 815/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 816/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.7ms\n",
      "video 1/1 (frame 817/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.8ms\n",
      "video 1/1 (frame 818/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.2ms\n",
      "video 1/1 (frame 819/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.3ms\n",
      "video 1/1 (frame 820/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 821/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 822/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 823/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.1ms\n",
      "video 1/1 (frame 824/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 825/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.6ms\n",
      "video 1/1 (frame 826/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.5ms\n",
      "video 1/1 (frame 827/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 828/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 829/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 830/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 831/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 832/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.4ms\n",
      "video 1/1 (frame 833/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 165.6ms\n",
      "video 1/1 (frame 834/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.0ms\n",
      "video 1/1 (frame 835/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.9ms\n",
      "video 1/1 (frame 836/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.3ms\n",
      "video 1/1 (frame 837/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.9ms\n",
      "video 1/1 (frame 838/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 839/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 840/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 841/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.0ms\n",
      "video 1/1 (frame 842/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 843/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.2ms\n",
      "video 1/1 (frame 844/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 845/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 846/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 847/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.2ms\n",
      "video 1/1 (frame 848/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.6ms\n",
      "video 1/1 (frame 849/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 850/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.6ms\n",
      "video 1/1 (frame 851/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.2ms\n",
      "video 1/1 (frame 852/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 853/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 854/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 855/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.2ms\n",
      "video 1/1 (frame 856/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 857/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.9ms\n",
      "video 1/1 (frame 858/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.8ms\n",
      "video 1/1 (frame 859/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.4ms\n",
      "video 1/1 (frame 860/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 861/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.8ms\n",
      "video 1/1 (frame 862/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.4ms\n",
      "video 1/1 (frame 863/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.3ms\n",
      "video 1/1 (frame 864/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 865/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.1ms\n",
      "video 1/1 (frame 866/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 143.3ms\n",
      "video 1/1 (frame 867/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.2ms\n",
      "video 1/1 (frame 868/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 869/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.7ms\n",
      "video 1/1 (frame 870/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 871/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.9ms\n",
      "video 1/1 (frame 872/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.6ms\n",
      "video 1/1 (frame 873/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.8ms\n",
      "video 1/1 (frame 874/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 875/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.0ms\n",
      "video 1/1 (frame 876/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.0ms\n",
      "video 1/1 (frame 877/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.7ms\n",
      "video 1/1 (frame 878/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.5ms\n",
      "video 1/1 (frame 879/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.1ms\n",
      "video 1/1 (frame 880/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.1ms\n",
      "video 1/1 (frame 881/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.6ms\n",
      "video 1/1 (frame 882/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.6ms\n",
      "video 1/1 (frame 883/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.8ms\n",
      "video 1/1 (frame 884/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.1ms\n",
      "video 1/1 (frame 885/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.7ms\n",
      "video 1/1 (frame 886/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 161.5ms\n",
      "video 1/1 (frame 887/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.7ms\n",
      "video 1/1 (frame 888/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 889/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.2ms\n",
      "video 1/1 (frame 890/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 891/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 892/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.9ms\n",
      "video 1/1 (frame 893/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.3ms\n",
      "video 1/1 (frame 894/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 895/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.7ms\n",
      "video 1/1 (frame 896/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 897/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 898/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.4ms\n",
      "video 1/1 (frame 899/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.1ms\n",
      "video 1/1 (frame 900/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.4ms\n",
      "video 1/1 (frame 901/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.4ms\n",
      "video 1/1 (frame 902/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.5ms\n",
      "video 1/1 (frame 903/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.3ms\n",
      "video 1/1 (frame 904/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 905/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.3ms\n",
      "video 1/1 (frame 906/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.5ms\n",
      "video 1/1 (frame 907/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.3ms\n",
      "video 1/1 (frame 908/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.7ms\n",
      "video 1/1 (frame 909/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.2ms\n",
      "video 1/1 (frame 910/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.5ms\n",
      "video 1/1 (frame 911/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.5ms\n",
      "video 1/1 (frame 912/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.3ms\n",
      "video 1/1 (frame 913/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 914/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 915/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.7ms\n",
      "video 1/1 (frame 916/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.6ms\n",
      "video 1/1 (frame 917/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.0ms\n",
      "video 1/1 (frame 918/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 150.5ms\n",
      "video 1/1 (frame 919/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 166.5ms\n",
      "video 1/1 (frame 920/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.0ms\n",
      "video 1/1 (frame 921/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.2ms\n",
      "video 1/1 (frame 922/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.8ms\n",
      "video 1/1 (frame 923/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 924/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.9ms\n",
      "video 1/1 (frame 925/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 926/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.6ms\n",
      "video 1/1 (frame 927/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.0ms\n",
      "video 1/1 (frame 928/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.7ms\n",
      "video 1/1 (frame 929/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.0ms\n",
      "video 1/1 (frame 930/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.5ms\n",
      "video 1/1 (frame 931/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 932/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 933/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 133.7ms\n",
      "video 1/1 (frame 934/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 153.2ms\n",
      "video 1/1 (frame 935/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.5ms\n",
      "video 1/1 (frame 936/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 292.1ms\n",
      "video 1/1 (frame 937/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 177.2ms\n",
      "video 1/1 (frame 938/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 179.7ms\n",
      "video 1/1 (frame 939/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 179.6ms\n",
      "video 1/1 (frame 940/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 180.3ms\n",
      "video 1/1 (frame 941/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 226.2ms\n",
      "video 1/1 (frame 942/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 215.1ms\n",
      "video 1/1 (frame 943/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 176.7ms\n",
      "video 1/1 (frame 944/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 173.6ms\n",
      "video 1/1 (frame 945/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 185.2ms\n",
      "video 1/1 (frame 946/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 177.7ms\n",
      "video 1/1 (frame 947/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 170.6ms\n",
      "video 1/1 (frame 948/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 167.1ms\n",
      "video 1/1 (frame 949/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 151.5ms\n",
      "video 1/1 (frame 950/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.1ms\n",
      "video 1/1 (frame 951/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.8ms\n",
      "video 1/1 (frame 952/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 133.1ms\n",
      "video 1/1 (frame 953/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.9ms\n",
      "video 1/1 (frame 954/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.8ms\n",
      "video 1/1 (frame 955/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 150.9ms\n",
      "video 1/1 (frame 956/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 156.5ms\n",
      "video 1/1 (frame 957/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.3ms\n",
      "video 1/1 (frame 958/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 133.9ms\n",
      "video 1/1 (frame 959/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 130.8ms\n",
      "video 1/1 (frame 960/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 132.8ms\n",
      "video 1/1 (frame 961/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 130.7ms\n",
      "video 1/1 (frame 962/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.8ms\n",
      "video 1/1 (frame 963/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.9ms\n",
      "video 1/1 (frame 964/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 965/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 966/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 967/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.5ms\n",
      "video 1/1 (frame 968/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.9ms\n",
      "video 1/1 (frame 969/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 137.8ms\n",
      "video 1/1 (frame 970/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 141.5ms\n",
      "video 1/1 (frame 971/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 972/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.0ms\n",
      "video 1/1 (frame 973/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 974/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.8ms\n",
      "video 1/1 (frame 975/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.1ms\n",
      "video 1/1 (frame 976/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.0ms\n",
      "video 1/1 (frame 977/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 978/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 979/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.0ms\n",
      "video 1/1 (frame 980/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 981/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.4ms\n",
      "video 1/1 (frame 982/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 983/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 984/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 985/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 986/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 987/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.0ms\n",
      "video 1/1 (frame 988/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 989/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 990/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 991/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 992/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.9ms\n",
      "video 1/1 (frame 993/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.5ms\n",
      "video 1/1 (frame 994/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 995/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 996/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 997/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.4ms\n",
      "video 1/1 (frame 998/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.8ms\n",
      "video 1/1 (frame 999/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.2ms\n",
      "video 1/1 (frame 1000/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.5ms\n",
      "video 1/1 (frame 1001/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.4ms\n",
      "video 1/1 (frame 1002/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 1003/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 1004/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.7ms\n",
      "video 1/1 (frame 1005/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 1006/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 1007/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.2ms\n",
      "video 1/1 (frame 1008/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.8ms\n",
      "video 1/1 (frame 1009/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.0ms\n",
      "video 1/1 (frame 1010/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.5ms\n",
      "video 1/1 (frame 1011/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.5ms\n",
      "video 1/1 (frame 1012/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 1013/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.1ms\n",
      "video 1/1 (frame 1014/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.9ms\n",
      "video 1/1 (frame 1015/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 1016/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.9ms\n",
      "video 1/1 (frame 1017/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 1018/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 1019/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.0ms\n",
      "video 1/1 (frame 1020/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 1021/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 1022/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.0ms\n",
      "video 1/1 (frame 1023/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 1024/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 1025/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.7ms\n",
      "video 1/1 (frame 1026/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.5ms\n",
      "video 1/1 (frame 1027/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 1028/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.8ms\n",
      "video 1/1 (frame 1029/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 1030/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.9ms\n",
      "video 1/1 (frame 1031/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.0ms\n",
      "video 1/1 (frame 1032/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 1033/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.6ms\n",
      "video 1/1 (frame 1034/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 1035/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.5ms\n",
      "video 1/1 (frame 1036/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.5ms\n",
      "video 1/1 (frame 1037/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.4ms\n",
      "video 1/1 (frame 1038/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.4ms\n",
      "video 1/1 (frame 1039/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.0ms\n",
      "video 1/1 (frame 1040/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.9ms\n",
      "video 1/1 (frame 1041/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.9ms\n",
      "video 1/1 (frame 1042/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 1043/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.8ms\n",
      "video 1/1 (frame 1044/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.6ms\n",
      "video 1/1 (frame 1045/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 1046/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.6ms\n",
      "video 1/1 (frame 1047/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.3ms\n",
      "video 1/1 (frame 1048/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 1049/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.6ms\n",
      "video 1/1 (frame 1050/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.3ms\n",
      "video 1/1 (frame 1051/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.1ms\n",
      "video 1/1 (frame 1052/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 168.1ms\n",
      "video 1/1 (frame 1053/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 1054/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.7ms\n",
      "video 1/1 (frame 1055/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.5ms\n",
      "video 1/1 (frame 1056/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 1057/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.0ms\n",
      "video 1/1 (frame 1058/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 1059/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 1060/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 1061/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.3ms\n",
      "video 1/1 (frame 1062/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.9ms\n",
      "video 1/1 (frame 1063/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 1064/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.2ms\n",
      "video 1/1 (frame 1065/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 1066/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 1067/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.3ms\n",
      "video 1/1 (frame 1068/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.2ms\n",
      "video 1/1 (frame 1069/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 1070/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 1071/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.1ms\n",
      "video 1/1 (frame 1072/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 1073/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 1074/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.5ms\n",
      "video 1/1 (frame 1075/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.4ms\n",
      "video 1/1 (frame 1076/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.5ms\n",
      "video 1/1 (frame 1077/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 1078/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.0ms\n",
      "video 1/1 (frame 1079/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.4ms\n",
      "video 1/1 (frame 1080/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.4ms\n",
      "video 1/1 (frame 1081/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.3ms\n",
      "video 1/1 (frame 1082/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.8ms\n",
      "video 1/1 (frame 1083/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 1084/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.5ms\n",
      "video 1/1 (frame 1085/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.5ms\n",
      "video 1/1 (frame 1086/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.0ms\n",
      "video 1/1 (frame 1087/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.1ms\n",
      "video 1/1 (frame 1088/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.3ms\n",
      "video 1/1 (frame 1089/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.0ms\n",
      "video 1/1 (frame 1090/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.1ms\n",
      "video 1/1 (frame 1091/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.8ms\n",
      "video 1/1 (frame 1092/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.1ms\n",
      "video 1/1 (frame 1093/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.5ms\n",
      "video 1/1 (frame 1094/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.4ms\n",
      "video 1/1 (frame 1095/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.6ms\n",
      "video 1/1 (frame 1096/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 1097/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.3ms\n",
      "video 1/1 (frame 1098/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.3ms\n",
      "video 1/1 (frame 1099/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 1100/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 1101/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 1102/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 156.5ms\n",
      "video 1/1 (frame 1103/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 160.0ms\n",
      "video 1/1 (frame 1104/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 154.9ms\n",
      "video 1/1 (frame 1105/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.8ms\n",
      "video 1/1 (frame 1106/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.3ms\n",
      "video 1/1 (frame 1107/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 172.9ms\n",
      "video 1/1 (frame 1108/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.9ms\n",
      "video 1/1 (frame 1109/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.2ms\n",
      "video 1/1 (frame 1110/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.0ms\n",
      "video 1/1 (frame 1111/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.1ms\n",
      "video 1/1 (frame 1112/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 1113/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.3ms\n",
      "video 1/1 (frame 1114/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 1115/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.0ms\n",
      "video 1/1 (frame 1116/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.6ms\n",
      "video 1/1 (frame 1117/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.5ms\n",
      "video 1/1 (frame 1118/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.5ms\n",
      "video 1/1 (frame 1119/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.9ms\n",
      "video 1/1 (frame 1120/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.8ms\n",
      "video 1/1 (frame 1121/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.8ms\n",
      "video 1/1 (frame 1122/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.3ms\n",
      "video 1/1 (frame 1123/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 1124/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.2ms\n",
      "video 1/1 (frame 1125/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.0ms\n",
      "video 1/1 (frame 1126/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.5ms\n",
      "video 1/1 (frame 1127/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.9ms\n",
      "video 1/1 (frame 1128/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.1ms\n",
      "video 1/1 (frame 1129/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.6ms\n",
      "video 1/1 (frame 1130/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.5ms\n",
      "video 1/1 (frame 1131/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 158.1ms\n",
      "video 1/1 (frame 1132/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 156.2ms\n",
      "video 1/1 (frame 1133/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.7ms\n",
      "video 1/1 (frame 1134/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.8ms\n",
      "video 1/1 (frame 1135/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 164.3ms\n",
      "video 1/1 (frame 1136/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 168.3ms\n",
      "video 1/1 (frame 1137/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 154.9ms\n",
      "video 1/1 (frame 1138/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 1139/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.2ms\n",
      "video 1/1 (frame 1140/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.8ms\n",
      "video 1/1 (frame 1141/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.9ms\n",
      "video 1/1 (frame 1142/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.1ms\n",
      "video 1/1 (frame 1143/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.1ms\n",
      "video 1/1 (frame 1144/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 1145/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 1146/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.3ms\n",
      "video 1/1 (frame 1147/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.0ms\n",
      "video 1/1 (frame 1148/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.6ms\n",
      "video 1/1 (frame 1149/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.0ms\n",
      "video 1/1 (frame 1150/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 1151/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.2ms\n",
      "video 1/1 (frame 1152/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.1ms\n",
      "video 1/1 (frame 1153/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 1154/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.4ms\n",
      "video 1/1 (frame 1155/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.2ms\n",
      "video 1/1 (frame 1156/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.3ms\n",
      "video 1/1 (frame 1157/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.5ms\n",
      "video 1/1 (frame 1158/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 1159/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 1160/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.0ms\n",
      "video 1/1 (frame 1161/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.1ms\n",
      "video 1/1 (frame 1162/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 160.3ms\n",
      "video 1/1 (frame 1163/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.7ms\n",
      "video 1/1 (frame 1164/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.6ms\n",
      "video 1/1 (frame 1165/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 1166/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.0ms\n",
      "video 1/1 (frame 1167/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.1ms\n",
      "video 1/1 (frame 1168/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.8ms\n",
      "video 1/1 (frame 1169/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 1170/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.0ms\n",
      "video 1/1 (frame 1171/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 1172/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 1173/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 1174/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.1ms\n",
      "video 1/1 (frame 1175/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.9ms\n",
      "video 1/1 (frame 1176/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 1177/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 150.3ms\n",
      "video 1/1 (frame 1178/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.1ms\n",
      "video 1/1 (frame 1179/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 1180/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 1181/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 141.7ms\n",
      "video 1/1 (frame 1182/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.9ms\n",
      "video 1/1 (frame 1183/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.5ms\n",
      "video 1/1 (frame 1184/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 222.2ms\n",
      "video 1/1 (frame 1185/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.5ms\n",
      "video 1/1 (frame 1186/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.9ms\n",
      "video 1/1 (frame 1187/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 1188/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 1189/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.5ms\n",
      "video 1/1 (frame 1190/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.6ms\n",
      "video 1/1 (frame 1191/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.3ms\n",
      "video 1/1 (frame 1192/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.2ms\n",
      "video 1/1 (frame 1193/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.9ms\n",
      "video 1/1 (frame 1194/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.2ms\n",
      "video 1/1 (frame 1195/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.8ms\n",
      "video 1/1 (frame 1196/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 1197/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 1198/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.2ms\n",
      "video 1/1 (frame 1199/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.7ms\n",
      "video 1/1 (frame 1200/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.5ms\n",
      "video 1/1 (frame 1201/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.5ms\n",
      "video 1/1 (frame 1202/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.8ms\n",
      "video 1/1 (frame 1203/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.2ms\n",
      "video 1/1 (frame 1204/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.8ms\n",
      "video 1/1 (frame 1205/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 158.7ms\n",
      "video 1/1 (frame 1206/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.5ms\n",
      "video 1/1 (frame 1207/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 1208/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.5ms\n",
      "video 1/1 (frame 1209/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.4ms\n",
      "video 1/1 (frame 1210/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 127.8ms\n",
      "video 1/1 (frame 1211/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 1212/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.8ms\n",
      "video 1/1 (frame 1213/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 1214/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 1215/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.5ms\n",
      "video 1/1 (frame 1216/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 167.1ms\n",
      "video 1/1 (frame 1217/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 1218/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.2ms\n",
      "video 1/1 (frame 1219/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 150.1ms\n",
      "video 1/1 (frame 1220/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.6ms\n",
      "video 1/1 (frame 1221/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 1222/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 165.6ms\n",
      "video 1/1 (frame 1223/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 148.1ms\n",
      "video 1/1 (frame 1224/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 1225/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 1410.1ms\n",
      "video 1/1 (frame 1226/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 194.0ms\n",
      "video 1/1 (frame 1227/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 159.7ms\n",
      "video 1/1 (frame 1228/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.9ms\n",
      "video 1/1 (frame 1229/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 162.6ms\n",
      "video 1/1 (frame 1230/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 155.0ms\n",
      "video 1/1 (frame 1231/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.6ms\n",
      "video 1/1 (frame 1232/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.2ms\n",
      "video 1/1 (frame 1233/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 1234/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.3ms\n",
      "video 1/1 (frame 1235/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 192.1ms\n",
      "video 1/1 (frame 1236/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.3ms\n",
      "video 1/1 (frame 1237/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.7ms\n",
      "video 1/1 (frame 1238/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.6ms\n",
      "video 1/1 (frame 1239/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.4ms\n",
      "video 1/1 (frame 1240/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 1241/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.3ms\n",
      "video 1/1 (frame 1242/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.7ms\n",
      "video 1/1 (frame 1243/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.4ms\n",
      "video 1/1 (frame 1244/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.4ms\n",
      "video 1/1 (frame 1245/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 1246/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.2ms\n",
      "video 1/1 (frame 1247/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.9ms\n",
      "video 1/1 (frame 1248/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.2ms\n",
      "video 1/1 (frame 1249/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 1250/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.9ms\n",
      "video 1/1 (frame 1251/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.6ms\n",
      "video 1/1 (frame 1252/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 155.4ms\n",
      "video 1/1 (frame 1253/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 160.7ms\n",
      "video 1/1 (frame 1254/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 1255/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 150.2ms\n",
      "video 1/1 (frame 1256/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.2ms\n",
      "video 1/1 (frame 1257/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.5ms\n",
      "video 1/1 (frame 1258/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.1ms\n",
      "video 1/1 (frame 1259/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 1260/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.2ms\n",
      "video 1/1 (frame 1261/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 1262/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.1ms\n",
      "video 1/1 (frame 1263/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.0ms\n",
      "video 1/1 (frame 1264/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.8ms\n",
      "video 1/1 (frame 1265/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.3ms\n",
      "video 1/1 (frame 1266/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.4ms\n",
      "video 1/1 (frame 1267/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 153.3ms\n",
      "video 1/1 (frame 1268/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 167.3ms\n",
      "video 1/1 (frame 1269/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.1ms\n",
      "video 1/1 (frame 1270/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.9ms\n",
      "video 1/1 (frame 1271/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.8ms\n",
      "video 1/1 (frame 1272/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.0ms\n",
      "video 1/1 (frame 1273/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.3ms\n",
      "video 1/1 (frame 1274/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 156.4ms\n",
      "video 1/1 (frame 1275/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 1276/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 1277/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 132.0ms\n",
      "video 1/1 (frame 1278/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.0ms\n",
      "video 1/1 (frame 1279/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.4ms\n",
      "video 1/1 (frame 1280/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.5ms\n",
      "video 1/1 (frame 1281/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 1282/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.5ms\n",
      "video 1/1 (frame 1283/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.8ms\n",
      "video 1/1 (frame 1284/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 1285/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.8ms\n",
      "video 1/1 (frame 1286/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 1287/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.1ms\n",
      "video 1/1 (frame 1288/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.5ms\n",
      "video 1/1 (frame 1289/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.6ms\n",
      "video 1/1 (frame 1290/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 1291/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.0ms\n",
      "video 1/1 (frame 1292/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.9ms\n",
      "video 1/1 (frame 1293/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.1ms\n",
      "video 1/1 (frame 1294/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.0ms\n",
      "video 1/1 (frame 1295/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 1296/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.5ms\n",
      "video 1/1 (frame 1297/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.2ms\n",
      "video 1/1 (frame 1298/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.4ms\n",
      "video 1/1 (frame 1299/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.9ms\n",
      "video 1/1 (frame 1300/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.5ms\n",
      "video 1/1 (frame 1301/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 1302/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 1303/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.6ms\n",
      "video 1/1 (frame 1304/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.1ms\n",
      "video 1/1 (frame 1305/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.6ms\n",
      "video 1/1 (frame 1306/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.4ms\n",
      "video 1/1 (frame 1307/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.3ms\n",
      "video 1/1 (frame 1308/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 1309/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.5ms\n",
      "video 1/1 (frame 1310/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.9ms\n",
      "video 1/1 (frame 1311/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.0ms\n",
      "video 1/1 (frame 1312/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 1313/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 130.9ms\n",
      "video 1/1 (frame 1314/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.9ms\n",
      "video 1/1 (frame 1315/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 160.7ms\n",
      "video 1/1 (frame 1316/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.6ms\n",
      "video 1/1 (frame 1317/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.2ms\n",
      "video 1/1 (frame 1318/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.7ms\n",
      "video 1/1 (frame 1319/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.4ms\n",
      "video 1/1 (frame 1320/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.0ms\n",
      "video 1/1 (frame 1321/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.9ms\n",
      "video 1/1 (frame 1322/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 1323/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 156.0ms\n",
      "video 1/1 (frame 1324/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 154.9ms\n",
      "video 1/1 (frame 1325/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.3ms\n",
      "video 1/1 (frame 1326/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 1327/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 1328/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.3ms\n",
      "video 1/1 (frame 1329/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.5ms\n",
      "video 1/1 (frame 1330/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.6ms\n",
      "video 1/1 (frame 1331/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.0ms\n",
      "video 1/1 (frame 1332/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.9ms\n",
      "video 1/1 (frame 1333/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 129.8ms\n",
      "video 1/1 (frame 1334/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.3ms\n",
      "video 1/1 (frame 1335/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.8ms\n",
      "video 1/1 (frame 1336/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.8ms\n",
      "video 1/1 (frame 1337/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.5ms\n",
      "video 1/1 (frame 1338/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 1339/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.8ms\n",
      "video 1/1 (frame 1340/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.9ms\n",
      "video 1/1 (frame 1341/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 127.0ms\n",
      "video 1/1 (frame 1342/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 126.6ms\n",
      "video 1/1 (frame 1343/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.2ms\n",
      "video 1/1 (frame 1344/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.3ms\n",
      "video 1/1 (frame 1345/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.6ms\n",
      "video 1/1 (frame 1346/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.8ms\n",
      "video 1/1 (frame 1347/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.3ms\n",
      "video 1/1 (frame 1348/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.7ms\n",
      "video 1/1 (frame 1349/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.7ms\n",
      "video 1/1 (frame 1350/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.9ms\n",
      "video 1/1 (frame 1351/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 1352/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 1353/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.6ms\n",
      "video 1/1 (frame 1354/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.8ms\n",
      "video 1/1 (frame 1355/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.9ms\n",
      "video 1/1 (frame 1356/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 149.5ms\n",
      "video 1/1 (frame 1357/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.4ms\n",
      "video 1/1 (frame 1358/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.1ms\n",
      "video 1/1 (frame 1359/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.3ms\n",
      "video 1/1 (frame 1360/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.3ms\n",
      "video 1/1 (frame 1361/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 161.9ms\n",
      "video 1/1 (frame 1362/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 130.1ms\n",
      "video 1/1 (frame 1363/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.8ms\n",
      "video 1/1 (frame 1364/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 1365/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.6ms\n",
      "video 1/1 (frame 1366/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.9ms\n",
      "video 1/1 (frame 1367/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 1368/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.1ms\n",
      "video 1/1 (frame 1369/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.6ms\n",
      "video 1/1 (frame 1370/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.1ms\n",
      "video 1/1 (frame 1371/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.0ms\n",
      "video 1/1 (frame 1372/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 1373/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.8ms\n",
      "video 1/1 (frame 1374/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.6ms\n",
      "video 1/1 (frame 1375/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 137.8ms\n",
      "video 1/1 (frame 1376/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.8ms\n",
      "video 1/1 (frame 1377/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 137.5ms\n",
      "video 1/1 (frame 1378/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.8ms\n",
      "video 1/1 (frame 1379/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 146.6ms\n",
      "video 1/1 (frame 1380/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.6ms\n",
      "video 1/1 (frame 1381/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.9ms\n",
      "video 1/1 (frame 1382/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 130.9ms\n",
      "video 1/1 (frame 1383/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 136.7ms\n",
      "video 1/1 (frame 1384/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.7ms\n",
      "video 1/1 (frame 1385/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 149.1ms\n",
      "video 1/1 (frame 1386/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 134.7ms\n",
      "video 1/1 (frame 1387/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.5ms\n",
      "video 1/1 (frame 1388/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 144.8ms\n",
      "video 1/1 (frame 1389/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.2ms\n",
      "video 1/1 (frame 1390/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.8ms\n",
      "video 1/1 (frame 1391/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 137.3ms\n",
      "video 1/1 (frame 1392/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 135.6ms\n",
      "video 1/1 (frame 1393/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 143.6ms\n",
      "video 1/1 (frame 1394/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.0ms\n",
      "video 1/1 (frame 1395/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.9ms\n",
      "video 1/1 (frame 1396/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.5ms\n",
      "video 1/1 (frame 1397/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.0ms\n",
      "video 1/1 (frame 1398/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 139.6ms\n",
      "video 1/1 (frame 1399/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.9ms\n",
      "video 1/1 (frame 1400/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 147.4ms\n",
      "video 1/1 (frame 1401/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 145.0ms\n",
      "video 1/1 (frame 1402/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 155.0ms\n",
      "video 1/1 (frame 1403/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 151.7ms\n",
      "video 1/1 (frame 1404/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 145.9ms\n",
      "video 1/1 (frame 1405/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 138.0ms\n",
      "video 1/1 (frame 1406/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 140.5ms\n",
      "video 1/1 (frame 1407/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 1 person, 141.6ms\n",
      "video 1/1 (frame 1408/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 3 persons, 136.2ms\n",
      "video 1/1 (frame 1409/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.3ms\n",
      "video 1/1 (frame 1410/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 1411/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.7ms\n",
      "video 1/1 (frame 1412/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.6ms\n",
      "video 1/1 (frame 1413/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.6ms\n",
      "video 1/1 (frame 1414/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.8ms\n",
      "video 1/1 (frame 1415/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.9ms\n",
      "video 1/1 (frame 1416/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.9ms\n",
      "video 1/1 (frame 1417/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 131.4ms\n",
      "video 1/1 (frame 1418/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.0ms\n",
      "video 1/1 (frame 1419/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 152.8ms\n",
      "video 1/1 (frame 1420/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 1421/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.5ms\n",
      "video 1/1 (frame 1422/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.8ms\n",
      "video 1/1 (frame 1423/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.2ms\n",
      "video 1/1 (frame 1424/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.3ms\n",
      "video 1/1 (frame 1425/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.7ms\n",
      "video 1/1 (frame 1426/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 145.1ms\n",
      "video 1/1 (frame 1427/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 153.5ms\n",
      "video 1/1 (frame 1428/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.5ms\n",
      "video 1/1 (frame 1429/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.1ms\n",
      "video 1/1 (frame 1430/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 1431/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.2ms\n",
      "video 1/1 (frame 1432/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.8ms\n",
      "video 1/1 (frame 1433/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.1ms\n",
      "video 1/1 (frame 1434/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.6ms\n",
      "video 1/1 (frame 1435/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.0ms\n",
      "video 1/1 (frame 1436/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 1437/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.1ms\n",
      "video 1/1 (frame 1438/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.5ms\n",
      "video 1/1 (frame 1439/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.5ms\n",
      "video 1/1 (frame 1440/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.6ms\n",
      "video 1/1 (frame 1441/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.7ms\n",
      "video 1/1 (frame 1442/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.2ms\n",
      "video 1/1 (frame 1443/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.2ms\n",
      "video 1/1 (frame 1444/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 128.7ms\n",
      "video 1/1 (frame 1445/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 171.1ms\n",
      "video 1/1 (frame 1446/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 127.8ms\n",
      "video 1/1 (frame 1447/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.7ms\n",
      "video 1/1 (frame 1448/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.0ms\n",
      "video 1/1 (frame 1449/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.7ms\n",
      "video 1/1 (frame 1450/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.4ms\n",
      "video 1/1 (frame 1451/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 132.8ms\n",
      "video 1/1 (frame 1452/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.7ms\n",
      "video 1/1 (frame 1453/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 133.2ms\n",
      "video 1/1 (frame 1454/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 139.3ms\n",
      "video 1/1 (frame 1455/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 143.3ms\n",
      "video 1/1 (frame 1456/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 136.1ms\n",
      "video 1/1 (frame 1457/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.2ms\n",
      "video 1/1 (frame 1458/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 142.1ms\n",
      "video 1/1 (frame 1459/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.5ms\n",
      "video 1/1 (frame 1460/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 144.5ms\n",
      "video 1/1 (frame 1461/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 134.6ms\n",
      "video 1/1 (frame 1462/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.4ms\n",
      "video 1/1 (frame 1463/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 1464/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 138.1ms\n",
      "video 1/1 (frame 1465/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.4ms\n",
      "video 1/1 (frame 1466/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.9ms\n",
      "video 1/1 (frame 1467/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 147.3ms\n",
      "video 1/1 (frame 1468/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 140.9ms\n",
      "video 1/1 (frame 1469/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 135.1ms\n",
      "video 1/1 (frame 1470/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 141.6ms\n",
      "video 1/1 (frame 1471/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.9ms\n",
      "video 1/1 (frame 1472/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 137.6ms\n",
      "video 1/1 (frame 1473/1473) D:\\college\\2024_spring\\AI\\project2\\.mp4: 384x640 2 persons, 151.7ms\n",
      "Speed: 1.5ms preprocess, 141.7ms inference, 0.7ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\pose\\predict9\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "model = YOLO('yolov8n-pose.pt')\n",
    "results = model(source=\"D:\\college\\\\2024_spring\\AI基础\\project2\\寒假打羽毛球的视频.mp4\", show=True, conf=0.3, save=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
